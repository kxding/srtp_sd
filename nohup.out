The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'CLIPTokenizer'. 
The class this function is called from is 'MultiTokenCLIPTokenizer'.
The config attributes {'dropout': 0.0} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.
/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
  warnings.warn(
/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:101: FutureWarning: The configuration file of this scheduler: DDIMScheduler {
  "_class_name": "DDIMScheduler",
  "_diffusers_version": "0.10.1",
  "beta_end": 0.012,
  "beta_schedule": "scaled_linear",
  "beta_start": 0.00085,
  "clip_sample": false,
  "num_train_timesteps": 1000,
  "prediction_type": "epsilon",
  "set_alpha_to_one": false,
  "steps_offset": 0,
  "trained_betas": null
}
 is outdated. `steps_offset` should be set to 1 instead of 0. Please make sure to update the config accordingly as leaving `steps_offset` might led to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json` file
  deprecate("steps_offset!=1", "1.0.0", deprecation_message, standard_warn=False)
use ref cfg: True
    Using ref classifier free guidance...
    guidance_scale_train_ref: 7.5
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:02, 19.26it/s] 10%|█         | 5/50 [00:00<00:02, 20.88it/s] 16%|█▌        | 8/50 [00:00<00:01, 21.39it/s] 22%|██▏       | 11/50 [00:00<00:01, 21.61it/s] 28%|██▊       | 14/50 [00:00<00:01, 21.77it/s] 34%|███▍      | 17/50 [00:00<00:01, 21.87it/s] 40%|████      | 20/50 [00:00<00:01, 21.89it/s] 46%|████▌     | 23/50 [00:01<00:01, 21.91it/s] 52%|█████▏    | 26/50 [00:01<00:01, 21.94it/s] 58%|█████▊    | 29/50 [00:01<00:00, 21.95it/s] 64%|██████▍   | 32/50 [00:01<00:00, 21.94it/s] 70%|███████   | 35/50 [00:01<00:00, 21.95it/s] 76%|███████▌  | 38/50 [00:01<00:00, 21.95it/s] 82%|████████▏ | 41/50 [00:01<00:00, 21.99it/s] 88%|████████▊ | 44/50 [00:02<00:00, 22.00it/s] 94%|█████████▍| 47/50 [00:02<00:00, 22.02it/s]100%|██████████| 50/50 [00:02<00:00, 21.96it/s]100%|██████████| 50/50 [00:02<00:00, 21.84it/s]
  0%|          | 0/2500 [00:00<?, ?it/s]  0%|          | 0/2500 [00:00<?, ?it/s, loss=2.95e-8]  0%|          | 1/2500 [00:00<08:32,  4.87it/s, loss=2.95e-8]  2%|▏         | 50/2500 [00:00<08:22,  4.87it/s, loss=1.88e-6]  2%|▏         | 51/2500 [00:00<00:19, 122.82it/s, loss=1.88e-6]  4%|▍         | 100/2500 [00:00<00:19, 122.82it/s, loss=1.94e-6]  4%|▍         | 101/2500 [00:00<00:15, 156.07it/s, loss=1.94e-6]  6%|▌         | 150/2500 [00:00<00:15, 156.07it/s, loss=1.39e-6]  6%|▌         | 151/2500 [00:00<00:13, 171.14it/s, loss=1.39e-6]  8%|▊         | 200/2500 [00:01<00:13, 171.14it/s, loss=3.66e-6]  8%|▊         | 201/2500 [00:01<00:12, 179.09it/s, loss=3.66e-6] 10%|█         | 250/2500 [00:01<00:12, 179.09it/s, loss=3.1e-6]  10%|█         | 251/2500 [00:01<00:12, 183.97it/s, loss=3.1e-6] 12%|█▏        | 300/2500 [00:01<00:11, 183.97it/s, loss=8.95e-6] 12%|█▏        | 301/2500 [00:01<00:11, 186.92it/s, loss=8.95e-6] 14%|█▍        | 350/2500 [00:02<00:11, 186.92it/s, loss=8.58e-6] 14%|█▍        | 351/2500 [00:02<00:11, 188.94it/s, loss=8.58e-6] 16%|█▌        | 400/2500 [00:02<00:11, 188.94it/s, loss=1.83e-5] 16%|█▌        | 401/2500 [00:02<00:11, 190.26it/s, loss=1.83e-5] 18%|█▊        | 450/2500 [00:02<00:10, 190.26it/s, loss=1.97e-5] 18%|█▊        | 451/2500 [00:02<00:10, 191.06it/s, loss=1.97e-5] 20%|██        | 500/2500 [00:02<00:10, 191.06it/s, loss=2.6e-5]  20%|██        | 501/2500 [00:02<00:10, 191.74it/s, loss=2.6e-5] 22%|██▏       | 550/2500 [00:03<00:10, 191.74it/s, loss=4.23e-5] 22%|██▏       | 551/2500 [00:03<00:10, 192.09it/s, loss=4.23e-5] 24%|██▍       | 600/2500 [00:03<00:09, 192.09it/s, loss=3.5e-5]  24%|██▍       | 601/2500 [00:03<00:09, 192.35it/s, loss=3.5e-5] 26%|██▌       | 650/2500 [00:03<00:09, 192.35it/s, loss=7.19e-5] 26%|██▌       | 651/2500 [00:03<00:09, 192.44it/s, loss=7.19e-5] 28%|██▊       | 700/2500 [00:03<00:09, 192.44it/s, loss=5e-5]    28%|██▊       | 701/2500 [00:03<00:09, 192.45it/s, loss=5e-5] 30%|███       | 750/2500 [00:04<00:09, 192.45it/s, loss=6.29e-5] 30%|███       | 751/2500 [00:04<00:09, 192.14it/s, loss=6.29e-5] 32%|███▏      | 800/2500 [00:04<00:08, 192.14it/s, loss=5.28e-5] 32%|███▏      | 801/2500 [00:04<00:08, 192.12it/s, loss=5.28e-5] 34%|███▍      | 850/2500 [00:04<00:08, 192.12it/s, loss=6.21e-5] 34%|███▍      | 851/2500 [00:04<00:08, 192.36it/s, loss=6.21e-5] 36%|███▌      | 900/2500 [00:04<00:08, 192.36it/s, loss=0.000101] 36%|███▌      | 901/2500 [00:04<00:08, 192.48it/s, loss=0.000101] 38%|███▊      | 950/2500 [00:05<00:08, 192.48it/s, loss=7.58e-5]  38%|███▊      | 951/2500 [00:05<00:08, 192.50it/s, loss=7.58e-5] 40%|████      | 1000/2500 [00:05<00:07, 192.50it/s, loss=0.000132] 40%|████      | 1001/2500 [00:05<00:07, 192.46it/s, loss=0.000132] 42%|████▏     | 1050/2500 [00:05<00:07, 192.46it/s, loss=9.12e-5]  42%|████▏     | 1051/2500 [00:05<00:07, 192.47it/s, loss=9.12e-5] 44%|████▍     | 1100/2500 [00:05<00:07, 192.47it/s, loss=0.000107] 44%|████▍     | 1101/2500 [00:05<00:07, 192.39it/s, loss=0.000107] 46%|████▌     | 1150/2500 [00:06<00:07, 192.39it/s, loss=0.000109] 46%|████▌     | 1151/2500 [00:06<00:07, 192.48it/s, loss=0.000109] 48%|████▊     | 1200/2500 [00:06<00:06, 192.48it/s, loss=0.000116] 48%|████▊     | 1201/2500 [00:06<00:06, 192.34it/s, loss=0.000116] 50%|█████     | 1250/2500 [00:06<00:06, 192.34it/s, loss=0.000125] 50%|█████     | 1251/2500 [00:06<00:06, 191.92it/s, loss=0.000125] 52%|█████▏    | 1300/2500 [00:06<00:06, 191.92it/s, loss=0.00013]  52%|█████▏    | 1301/2500 [00:06<00:06, 191.95it/s, loss=0.00013] 54%|█████▍    | 1350/2500 [00:07<00:05, 191.95it/s, loss=0.000142] 54%|█████▍    | 1351/2500 [00:07<00:05, 192.15it/s, loss=0.000142] 56%|█████▌    | 1400/2500 [00:07<00:05, 192.15it/s, loss=0.000149] 56%|█████▌    | 1401/2500 [00:07<00:05, 192.25it/s, loss=0.000149] 58%|█████▊    | 1450/2500 [00:07<00:05, 192.25it/s, loss=0.00016]  58%|█████▊    | 1451/2500 [00:07<00:05, 192.21it/s, loss=0.00016] 60%|██████    | 1500/2500 [00:08<00:05, 192.21it/s, loss=0.000171] 60%|██████    | 1501/2500 [00:08<00:05, 192.27it/s, loss=0.000171] 62%|██████▏   | 1550/2500 [00:08<00:04, 192.27it/s, loss=0.000182] 62%|██████▏   | 1551/2500 [00:08<00:04, 192.16it/s, loss=0.000182] 64%|██████▍   | 1600/2500 [00:08<00:04, 192.16it/s, loss=0.000193] 64%|██████▍   | 1601/2500 [00:08<00:04, 191.92it/s, loss=0.000193] 66%|██████▌   | 1650/2500 [00:08<00:04, 191.92it/s, loss=0.000203] 66%|██████▌   | 1651/2500 [00:08<00:04, 191.66it/s, loss=0.000203] 68%|██████▊   | 1700/2500 [00:09<00:04, 191.66it/s, loss=0.000214] 68%|██████▊   | 1701/2500 [00:09<00:04, 191.84it/s, loss=0.000214] 70%|███████   | 1750/2500 [00:09<00:03, 191.84it/s, loss=0.000224] 70%|███████   | 1751/2500 [00:09<00:03, 191.83it/s, loss=0.000224] 72%|███████▏  | 1800/2500 [00:09<00:03, 191.83it/s, loss=0.000236] 72%|███████▏  | 1801/2500 [00:09<00:03, 191.47it/s, loss=0.000236] 74%|███████▍  | 1850/2500 [00:09<00:03, 191.47it/s, loss=0.000247] 74%|███████▍  | 1851/2500 [00:09<00:03, 191.78it/s, loss=0.000247] 76%|███████▌  | 1900/2500 [00:10<00:03, 191.78it/s, loss=0.00026]  76%|███████▌  | 1901/2500 [00:10<00:03, 191.91it/s, loss=0.00026] 78%|███████▊  | 1950/2500 [00:10<00:02, 191.91it/s, loss=0.000272] 78%|███████▊  | 1951/2500 [00:10<00:02, 191.16it/s, loss=0.000272] 80%|████████  | 2000/2500 [00:10<00:02, 191.16it/s, loss=0.000285] 80%|████████  | 2001/2500 [00:10<00:02, 191.37it/s, loss=0.000285] 82%|████████▏ | 2050/2500 [00:10<00:02, 191.37it/s, loss=0.0003]   82%|████████▏ | 2051/2500 [00:10<00:02, 191.59it/s, loss=0.0003] 84%|████████▍ | 2100/2500 [00:11<00:02, 191.59it/s, loss=0.000315] 84%|████████▍ | 2101/2500 [00:11<00:02, 191.58it/s, loss=0.000315] 86%|████████▌ | 2150/2500 [00:11<00:01, 191.58it/s, loss=0.000333] 86%|████████▌ | 2151/2500 [00:11<00:01, 191.43it/s, loss=0.000333] 88%|████████▊ | 2200/2500 [00:11<00:01, 191.43it/s, loss=0.000354] 88%|████████▊ | 2201/2500 [00:11<00:01, 191.55it/s, loss=0.000354] 90%|█████████ | 2250/2500 [00:11<00:01, 191.55it/s, loss=0.000381] 90%|█████████ | 2251/2500 [00:11<00:01, 191.77it/s, loss=0.000381] 92%|█████████▏| 2300/2500 [00:12<00:01, 191.77it/s, loss=0.000419] 92%|█████████▏| 2301/2500 [00:12<00:01, 191.85it/s, loss=0.000419] 94%|█████████▍| 2350/2500 [00:12<00:00, 191.85it/s, loss=0.000481] 94%|█████████▍| 2351/2500 [00:12<00:00, 191.57it/s, loss=0.000481] 96%|█████████▌| 2400/2500 [00:12<00:00, 191.57it/s, loss=0.00073]  96%|█████████▌| 2401/2500 [00:12<00:00, 191.30it/s, loss=0.00073] 98%|█████████▊| 2450/2500 [00:12<00:00, 191.30it/s, loss=0.000709] 98%|█████████▊| 2451/2500 [00:12<00:00, 191.62it/s, loss=0.000709]100%|██████████| 2500/2500 [00:13<00:00, 192.25it/s, loss=0.000709]
/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/accelerate/accelerator.py:321: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
12/07/2023 16:47:47 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Mixed precision type: no

The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'CLIPTokenizer'. 
The class this function is called from is 'MultiTokenCLIPTokenizer'.
The config attributes {'set_alpha_to_one': False, 'skip_prk_steps': True, 'steps_offset': 1} were passed to DDPMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.
{'variance_type', 'clip_sample'} was not found in config. Values will be initialized to default values.
The config attributes {'dropout': 0.0} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.
{'mid_block_scale_factor', 'upcast_attention', 'use_linear_projection', 'center_input_sample', 'downsample_padding', 'dual_cross_attention', 'act_fn', 'only_cross_attention', 'norm_num_groups', 'norm_eps', 'flip_sin_to_cos', 'num_class_embeds'} was not found in config. Values will be initialized to default values.
12/07/2023 16:52:12 - INFO - __main__ - ***** Running training *****
12/07/2023 16:52:12 - INFO - __main__ -   Num examples = 100
12/07/2023 16:52:12 - INFO - __main__ -   Num Epochs = 4
12/07/2023 16:52:12 - INFO - __main__ -   Instantaneous batch size per device = 1
12/07/2023 16:52:12 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
12/07/2023 16:52:12 - INFO - __main__ -   Gradient Accumulation steps = 4
12/07/2023 16:52:12 - INFO - __main__ -   Total optimization steps = 100
number of placeholder tokens are: 3
  0%|          | 0/100 [00:00<?, ?it/s]Steps:   0%|          | 0/100 [00:00<?, ?it/s]/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
main.py:802: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  src_pred = unet(noisy_latents, timesteps, src_embedding_list[timesteps // 20]).sample
Steps:   0%|          | 0/100 [00:00<?, ?it/s, loss=0.467, lr=0.002]Steps:   0%|          | 0/100 [00:00<?, ?it/s, loss=0.577, lr=0.002]Steps:   0%|          | 0/100 [00:00<?, ?it/s, loss=0.403, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:43,  1.05s/it, loss=0.403, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:43,  1.05s/it, loss=0.443, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:43,  1.05s/it, loss=0.558, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:43,  1.05s/it, loss=0.534, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:43,  1.05s/it, loss=0.557, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:42,  1.05s/it, loss=0.557, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:42,  1.05s/it, loss=0.569, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:42,  1.05s/it, loss=0.586, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:42,  1.05s/it, loss=0.569, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:42,  1.05s/it, loss=0.487, lr=0.002]Steps:   3%|▎         | 3/100 [00:03<01:41,  1.05s/it, loss=0.487, lr=0.002]Steps:   3%|▎         | 3/100 [00:03<01:41,  1.05s/it, loss=0.584, lr=0.002]Steps:   3%|▎         | 3/100 [00:03<01:41,  1.05s/it, loss=0.568, lr=0.002]Steps:   3%|▎         | 3/100 [00:03<01:41,  1.05s/it, loss=0.601, lr=0.002]Steps:   3%|▎         | 3/100 [00:03<01:41,  1.05s/it, loss=0.566, lr=0.002]Steps:   4%|▍         | 4/100 [00:04<01:40,  1.05s/it, loss=0.566, lr=0.002]Steps:   4%|▍         | 4/100 [00:04<01:40,  1.05s/it, loss=0.439, lr=0.002]Steps:   4%|▍         | 4/100 [00:04<01:40,  1.05s/it, loss=0.533, lr=0.002]Steps:   4%|▍         | 4/100 [00:04<01:40,  1.05s/it, loss=0.388, lr=0.002]Steps:   4%|▍         | 4/100 [00:04<01:40,  1.05s/it, loss=0.38, lr=0.002] Steps:   5%|▌         | 5/100 [00:05<01:39,  1.05s/it, loss=0.38, lr=0.002]Steps:   5%|▌         | 5/100 [00:05<01:39,  1.05s/it, loss=0.56, lr=0.002]Steps:   5%|▌         | 5/100 [00:05<01:39,  1.05s/it, loss=0.475, lr=0.002]Steps:   5%|▌         | 5/100 [00:05<01:39,  1.05s/it, loss=0.608, lr=0.002]Steps:   5%|▌         | 5/100 [00:06<01:39,  1.05s/it, loss=0.592, lr=0.002]Steps:   6%|▌         | 6/100 [00:06<01:38,  1.04s/it, loss=0.592, lr=0.002]Steps:   6%|▌         | 6/100 [00:06<01:38,  1.04s/it, loss=0.566, lr=0.002]Steps:   6%|▌         | 6/100 [00:06<01:38,  1.04s/it, loss=0.567, lr=0.002]Steps:   6%|▌         | 6/100 [00:06<01:38,  1.04s/it, loss=0.571, lr=0.002]Steps:   6%|▌         | 6/100 [00:07<01:38,  1.04s/it, loss=0.575, lr=0.002]Steps:   7%|▋         | 7/100 [00:07<01:37,  1.04s/it, loss=0.575, lr=0.002]Steps:   7%|▋         | 7/100 [00:07<01:37,  1.04s/it, loss=0.551, lr=0.002]Steps:   7%|▋         | 7/100 [00:07<01:37,  1.04s/it, loss=0.566, lr=0.002]Steps:   7%|▋         | 7/100 [00:07<01:37,  1.04s/it, loss=0.581, lr=0.002]Steps:   7%|▋         | 7/100 [00:08<01:37,  1.04s/it, loss=0.573, lr=0.002]Steps:   8%|▊         | 8/100 [00:08<01:36,  1.04s/it, loss=0.573, lr=0.002]Steps:   8%|▊         | 8/100 [00:08<01:36,  1.04s/it, loss=0.542, lr=0.002]Steps:   8%|▊         | 8/100 [00:08<01:36,  1.04s/it, loss=0.565, lr=0.002]Steps:   8%|▊         | 8/100 [00:08<01:36,  1.04s/it, loss=0.615, lr=0.002]Steps:   8%|▊         | 8/100 [00:09<01:36,  1.04s/it, loss=0.579, lr=0.002]Steps:   9%|▉         | 9/100 [00:09<01:34,  1.04s/it, loss=0.579, lr=0.002]Steps:   9%|▉         | 9/100 [00:09<01:34,  1.04s/it, loss=0.574, lr=0.002]Steps:   9%|▉         | 9/100 [00:09<01:34,  1.04s/it, loss=0.615, lr=0.002]Steps:   9%|▉         | 9/100 [00:09<01:34,  1.04s/it, loss=0.569, lr=0.002]Steps:   9%|▉         | 9/100 [00:10<01:34,  1.04s/it, loss=0.534, lr=0.002]Steps:  10%|█         | 10/100 [00:10<01:33,  1.04s/it, loss=0.534, lr=0.002]Steps:  10%|█         | 10/100 [00:10<01:33,  1.04s/it, loss=0.465, lr=0.002]Steps:  10%|█         | 10/100 [00:10<01:33,  1.04s/it, loss=0.567, lr=0.002]Steps:  10%|█         | 10/100 [00:10<01:33,  1.04s/it, loss=0.415, lr=0.002]Steps:  10%|█         | 10/100 [00:11<01:33,  1.04s/it, loss=0.568, lr=0.002]Steps:  11%|█         | 11/100 [00:11<01:32,  1.04s/it, loss=0.568, lr=0.002]Steps:  11%|█         | 11/100 [00:11<01:32,  1.04s/it, loss=0.481, lr=0.002]Steps:  11%|█         | 11/100 [00:11<01:32,  1.04s/it, loss=0.412, lr=0.002]Steps:  11%|█         | 11/100 [00:12<01:32,  1.04s/it, loss=0.585, lr=0.002]Steps:  11%|█         | 11/100 [00:12<01:32,  1.04s/it, loss=0.578, lr=0.002]Steps:  12%|█▏        | 12/100 [00:12<01:31,  1.04s/it, loss=0.578, lr=0.002]Steps:  12%|█▏        | 12/100 [00:12<01:31,  1.04s/it, loss=0.541, lr=0.002]Steps:  12%|█▏        | 12/100 [00:12<01:31,  1.04s/it, loss=0.487, lr=0.002]Steps:  12%|█▏        | 12/100 [00:13<01:31,  1.04s/it, loss=0.516, lr=0.002]Steps:  12%|█▏        | 12/100 [00:13<01:31,  1.04s/it, loss=0.418, lr=0.002]Steps:  13%|█▎        | 13/100 [00:13<01:30,  1.04s/it, loss=0.418, lr=0.002]Steps:  13%|█▎        | 13/100 [00:13<01:30,  1.04s/it, loss=0.565, lr=0.002]Steps:  13%|█▎        | 13/100 [00:13<01:30,  1.04s/it, loss=0.468, lr=0.002]Steps:  13%|█▎        | 13/100 [00:14<01:30,  1.04s/it, loss=0.546, lr=0.002]Steps:  13%|█▎        | 13/100 [00:14<01:30,  1.04s/it, loss=0.582, lr=0.002]Steps:  14%|█▍        | 14/100 [00:14<01:29,  1.04s/it, loss=0.582, lr=0.002]Steps:  14%|█▍        | 14/100 [00:14<01:29,  1.04s/it, loss=0.557, lr=0.002]Steps:  14%|█▍        | 14/100 [00:14<01:29,  1.04s/it, loss=0.628, lr=0.002]Steps:  14%|█▍        | 14/100 [00:15<01:29,  1.04s/it, loss=0.609, lr=0.002]Steps:  14%|█▍        | 14/100 [00:15<01:29,  1.04s/it, loss=0.428, lr=0.002]Steps:  15%|█▌        | 15/100 [00:15<01:28,  1.04s/it, loss=0.428, lr=0.002]Steps:  15%|█▌        | 15/100 [00:15<01:28,  1.04s/it, loss=0.551, lr=0.002]Steps:  15%|█▌        | 15/100 [00:15<01:28,  1.04s/it, loss=0.482, lr=0.002]Steps:  15%|█▌        | 15/100 [00:16<01:28,  1.04s/it, loss=0.589, lr=0.002]Steps:  15%|█▌        | 15/100 [00:16<01:28,  1.04s/it, loss=0.566, lr=0.002]Steps:  16%|█▌        | 16/100 [00:16<01:27,  1.04s/it, loss=0.566, lr=0.002]Steps:  16%|█▌        | 16/100 [00:16<01:27,  1.04s/it, loss=0.576, lr=0.002]Steps:  16%|█▌        | 16/100 [00:16<01:27,  1.04s/it, loss=0.593, lr=0.002]Steps:  16%|█▌        | 16/100 [00:17<01:27,  1.04s/it, loss=0.483, lr=0.002]Steps:  16%|█▌        | 16/100 [00:17<01:27,  1.04s/it, loss=0.569, lr=0.002]Steps:  17%|█▋        | 17/100 [00:17<01:26,  1.04s/it, loss=0.569, lr=0.002]Steps:  17%|█▋        | 17/100 [00:17<01:26,  1.04s/it, loss=0.537, lr=0.002]Steps:  17%|█▋        | 17/100 [00:17<01:26,  1.04s/it, loss=0.496, lr=0.002]Steps:  17%|█▋        | 17/100 [00:18<01:26,  1.04s/it, loss=0.425, lr=0.002]Steps:  17%|█▋        | 17/100 [00:18<01:26,  1.04s/it, loss=0.561, lr=0.002]Steps:  18%|█▊        | 18/100 [00:18<01:25,  1.04s/it, loss=0.561, lr=0.002]Steps:  18%|█▊        | 18/100 [00:18<01:25,  1.04s/it, loss=0.571, lr=0.002]Steps:  18%|█▊        | 18/100 [00:19<01:25,  1.04s/it, loss=0.552, lr=0.002]Steps:  18%|█▊        | 18/100 [00:19<01:25,  1.04s/it, loss=0.388, lr=0.002]Steps:  18%|█▊        | 18/100 [00:19<01:25,  1.04s/it, loss=0.567, lr=0.002]Steps:  19%|█▉        | 19/100 [00:19<01:24,  1.04s/it, loss=0.567, lr=0.002]Steps:  19%|█▉        | 19/100 [00:19<01:24,  1.04s/it, loss=0.578, lr=0.002]Steps:  19%|█▉        | 19/100 [00:20<01:24,  1.04s/it, loss=0.591, lr=0.002]Steps:  19%|█▉        | 19/100 [00:20<01:24,  1.04s/it, loss=0.552, lr=0.002]Steps:  19%|█▉        | 19/100 [00:20<01:24,  1.04s/it, loss=0.452, lr=0.002]Steps:  20%|██        | 20/100 [00:20<01:23,  1.04s/it, loss=0.452, lr=0.002]Steps:  20%|██        | 20/100 [00:20<01:23,  1.04s/it, loss=0.587, lr=0.002]Steps:  20%|██        | 20/100 [00:21<01:23,  1.04s/it, loss=0.47, lr=0.002] Steps:  20%|██        | 20/100 [00:21<01:23,  1.04s/it, loss=0.571, lr=0.002]Steps:  20%|██        | 20/100 [00:21<01:23,  1.04s/it, loss=0.502, lr=0.002]Steps:  21%|██        | 21/100 [00:21<01:22,  1.04s/it, loss=0.502, lr=0.002]Steps:  21%|██        | 21/100 [00:21<01:22,  1.04s/it, loss=0.577, lr=0.002]Steps:  21%|██        | 21/100 [00:22<01:22,  1.04s/it, loss=0.566, lr=0.002]Steps:  21%|██        | 21/100 [00:22<01:22,  1.04s/it, loss=0.484, lr=0.002]Steps:  21%|██        | 21/100 [00:22<01:22,  1.04s/it, loss=0.573, lr=0.002]Steps:  22%|██▏       | 22/100 [00:22<01:21,  1.04s/it, loss=0.573, lr=0.002]Steps:  22%|██▏       | 22/100 [00:22<01:21,  1.04s/it, loss=0.54, lr=0.002] Steps:  22%|██▏       | 22/100 [00:23<01:21,  1.04s/it, loss=0.549, lr=0.002]Steps:  22%|██▏       | 22/100 [00:23<01:21,  1.04s/it, loss=0.406, lr=0.002]Steps:  22%|██▏       | 22/100 [00:23<01:21,  1.04s/it, loss=0.398, lr=0.002]Steps:  23%|██▎       | 23/100 [00:23<01:20,  1.04s/it, loss=0.398, lr=0.002]Steps:  23%|██▎       | 23/100 [00:23<01:20,  1.04s/it, loss=0.59, lr=0.002] Steps:  23%|██▎       | 23/100 [00:24<01:20,  1.04s/it, loss=0.398, lr=0.002]Steps:  23%|██▎       | 23/100 [00:24<01:20,  1.04s/it, loss=0.404, lr=0.002]Steps:  23%|██▎       | 23/100 [00:24<01:20,  1.04s/it, loss=0.492, lr=0.002]Steps:  24%|██▍       | 24/100 [00:25<01:19,  1.04s/it, loss=0.492, lr=0.002]Steps:  24%|██▍       | 24/100 [00:25<01:19,  1.04s/it, loss=0.423, lr=0.002]Steps:  24%|██▍       | 24/100 [00:25<01:19,  1.04s/it, loss=0.563, lr=0.002]Steps:  24%|██▍       | 24/100 [00:25<01:19,  1.04s/it, loss=0.476, lr=0.002]Steps:  24%|██▍       | 24/100 [00:25<01:19,  1.04s/it, loss=0.416, lr=0.002]Steps:  25%|██▌       | 25/100 [00:26<01:17,  1.03s/it, loss=0.416, lr=0.002]Steps:  25%|██▌       | 25/100 [00:26<01:17,  1.03s/it, loss=0.577, lr=0.002]Steps:  25%|██▌       | 25/100 [00:26<01:17,  1.03s/it, loss=0.501, lr=0.002]Steps:  25%|██▌       | 25/100 [00:26<01:17,  1.03s/it, loss=0.411, lr=0.002]Steps:  25%|██▌       | 25/100 [00:26<01:17,  1.03s/it, loss=0.38, lr=0.002] Steps:  26%|██▌       | 26/100 [00:27<01:17,  1.04s/it, loss=0.38, lr=0.002]Steps:  26%|██▌       | 26/100 [00:27<01:17,  1.04s/it, loss=0.452, lr=0.002]Steps:  26%|██▌       | 26/100 [00:27<01:17,  1.04s/it, loss=0.533, lr=0.002]Steps:  26%|██▌       | 26/100 [00:27<01:17,  1.04s/it, loss=0.571, lr=0.002]Steps:  26%|██▌       | 26/100 [00:27<01:17,  1.04s/it, loss=0.422, lr=0.002]Steps:  27%|██▋       | 27/100 [00:28<01:16,  1.04s/it, loss=0.422, lr=0.002]Steps:  27%|██▋       | 27/100 [00:28<01:16,  1.04s/it, loss=0.398, lr=0.002]Steps:  27%|██▋       | 27/100 [00:28<01:16,  1.04s/it, loss=0.552, lr=0.002]Steps:  27%|██▋       | 27/100 [00:28<01:16,  1.04s/it, loss=0.516, lr=0.002]Steps:  27%|██▋       | 27/100 [00:28<01:16,  1.04s/it, loss=0.564, lr=0.002]Steps:  28%|██▊       | 28/100 [00:29<01:15,  1.05s/it, loss=0.564, lr=0.002]Steps:  28%|██▊       | 28/100 [00:29<01:15,  1.05s/it, loss=0.568, lr=0.002]Steps:  28%|██▊       | 28/100 [00:29<01:15,  1.05s/it, loss=0.578, lr=0.002]Steps:  28%|██▊       | 28/100 [00:29<01:15,  1.05s/it, loss=0.512, lr=0.002]Steps:  28%|██▊       | 28/100 [00:29<01:15,  1.05s/it, loss=0.55, lr=0.002] Steps:  29%|██▉       | 29/100 [00:30<01:14,  1.04s/it, loss=0.55, lr=0.002]Steps:  29%|██▉       | 29/100 [00:30<01:14,  1.04s/it, loss=0.381, lr=0.002]Steps:  29%|██▉       | 29/100 [00:30<01:14,  1.04s/it, loss=0.47, lr=0.002] Steps:  29%|██▉       | 29/100 [00:30<01:14,  1.04s/it, loss=0.567, lr=0.002]Steps:  29%|██▉       | 29/100 [00:31<01:14,  1.04s/it, loss=0.554, lr=0.002]Steps:  30%|███       | 30/100 [00:31<01:12,  1.04s/it, loss=0.554, lr=0.002]Steps:  30%|███       | 30/100 [00:31<01:12,  1.04s/it, loss=0.488, lr=0.002]Steps:  30%|███       | 30/100 [00:31<01:12,  1.04s/it, loss=0.41, lr=0.002] Steps:  30%|███       | 30/100 [00:31<01:12,  1.04s/it, loss=0.437, lr=0.002]Steps:  30%|███       | 30/100 [00:32<01:12,  1.04s/it, loss=0.583, lr=0.002]Steps:  31%|███       | 31/100 [00:32<01:11,  1.04s/it, loss=0.583, lr=0.002]Steps:  31%|███       | 31/100 [00:32<01:11,  1.04s/it, loss=0.522, lr=0.002]Steps:  31%|███       | 31/100 [00:32<01:11,  1.04s/it, loss=0.403, lr=0.002]Steps:  31%|███       | 31/100 [00:32<01:11,  1.04s/it, loss=0.574, lr=0.002]Steps:  31%|███       | 31/100 [00:33<01:11,  1.04s/it, loss=0.592, lr=0.002]Steps:  32%|███▏      | 32/100 [00:33<01:10,  1.04s/it, loss=0.592, lr=0.002]Steps:  32%|███▏      | 32/100 [00:33<01:10,  1.04s/it, loss=0.492, lr=0.002]Steps:  32%|███▏      | 32/100 [00:33<01:10,  1.04s/it, loss=0.553, lr=0.002]Steps:  32%|███▏      | 32/100 [00:33<01:10,  1.04s/it, loss=0.573, lr=0.002]Steps:  32%|███▏      | 32/100 [00:34<01:10,  1.04s/it, loss=0.541, lr=0.002]Steps:  33%|███▎      | 33/100 [00:34<01:09,  1.04s/it, loss=0.541, lr=0.002]Steps:  33%|███▎      | 33/100 [00:34<01:09,  1.04s/it, loss=0.583, lr=0.002]Steps:  33%|███▎      | 33/100 [00:34<01:09,  1.04s/it, loss=0.567, lr=0.002]Steps:  33%|███▎      | 33/100 [00:34<01:09,  1.04s/it, loss=0.44, lr=0.002] Steps:  33%|███▎      | 33/100 [00:35<01:09,  1.04s/it, loss=0.427, lr=0.002]Steps:  34%|███▍      | 34/100 [00:35<01:08,  1.04s/it, loss=0.427, lr=0.002]Steps:  34%|███▍      | 34/100 [00:35<01:08,  1.04s/it, loss=0.427, lr=0.002]Steps:  34%|███▍      | 34/100 [00:35<01:08,  1.04s/it, loss=0.569, lr=0.002]Steps:  34%|███▍      | 34/100 [00:35<01:08,  1.04s/it, loss=0.577, lr=0.002]Steps:  34%|███▍      | 34/100 [00:36<01:08,  1.04s/it, loss=0.595, lr=0.002]Steps:  35%|███▌      | 35/100 [00:36<01:07,  1.04s/it, loss=0.595, lr=0.002]Steps:  35%|███▌      | 35/100 [00:36<01:07,  1.04s/it, loss=0.57, lr=0.002] Steps:  35%|███▌      | 35/100 [00:36<01:07,  1.04s/it, loss=0.569, lr=0.002]Steps:  35%|███▌      | 35/100 [00:36<01:07,  1.04s/it, loss=0.5, lr=0.002]  Steps:  35%|███▌      | 35/100 [00:37<01:07,  1.04s/it, loss=0.386, lr=0.002]Steps:  36%|███▌      | 36/100 [00:37<01:06,  1.04s/it, loss=0.386, lr=0.002]Steps:  36%|███▌      | 36/100 [00:37<01:06,  1.04s/it, loss=0.575, lr=0.002]Steps:  36%|███▌      | 36/100 [00:37<01:06,  1.04s/it, loss=0.453, lr=0.002]Steps:  36%|███▌      | 36/100 [00:38<01:06,  1.04s/it, loss=0.436, lr=0.002]Steps:  36%|███▌      | 36/100 [00:38<01:06,  1.04s/it, loss=0.446, lr=0.002]Steps:  37%|███▋      | 37/100 [00:38<01:05,  1.04s/it, loss=0.446, lr=0.002]Steps:  37%|███▋      | 37/100 [00:38<01:05,  1.04s/it, loss=0.376, lr=0.002]Steps:  37%|███▋      | 37/100 [00:38<01:05,  1.04s/it, loss=0.563, lr=0.002]Steps:  37%|███▋      | 37/100 [00:39<01:05,  1.04s/it, loss=0.536, lr=0.002]Steps:  37%|███▋      | 37/100 [00:39<01:05,  1.04s/it, loss=0.494, lr=0.002]Steps:  38%|███▊      | 38/100 [00:39<01:04,  1.04s/it, loss=0.494, lr=0.002]Steps:  38%|███▊      | 38/100 [00:39<01:04,  1.04s/it, loss=0.581, lr=0.002]Steps:  38%|███▊      | 38/100 [00:39<01:04,  1.04s/it, loss=0.395, lr=0.002]Steps:  38%|███▊      | 38/100 [00:40<01:04,  1.04s/it, loss=0.502, lr=0.002]Steps:  38%|███▊      | 38/100 [00:40<01:04,  1.04s/it, loss=0.389, lr=0.002]Steps:  39%|███▉      | 39/100 [00:40<01:03,  1.04s/it, loss=0.389, lr=0.002]Steps:  39%|███▉      | 39/100 [00:40<01:03,  1.04s/it, loss=0.559, lr=0.002]Steps:  39%|███▉      | 39/100 [00:40<01:03,  1.04s/it, loss=0.523, lr=0.002]Steps:  39%|███▉      | 39/100 [00:41<01:03,  1.04s/it, loss=0.506, lr=0.002]Steps:  39%|███▉      | 39/100 [00:41<01:03,  1.04s/it, loss=0.57, lr=0.002] Steps:  40%|████      | 40/100 [00:41<01:02,  1.04s/it, loss=0.57, lr=0.002]Steps:  40%|████      | 40/100 [00:41<01:02,  1.04s/it, loss=0.389, lr=0.002]Steps:  40%|████      | 40/100 [00:41<01:02,  1.04s/it, loss=0.439, lr=0.002]Steps:  40%|████      | 40/100 [00:42<01:02,  1.04s/it, loss=0.488, lr=0.002]Steps:  40%|████      | 40/100 [00:42<01:02,  1.04s/it, loss=0.563, lr=0.002]Steps:  41%|████      | 41/100 [00:42<01:01,  1.04s/it, loss=0.563, lr=0.002]Steps:  41%|████      | 41/100 [00:42<01:01,  1.04s/it, loss=0.395, lr=0.002]Steps:  41%|████      | 41/100 [00:42<01:01,  1.04s/it, loss=0.568, lr=0.002]Steps:  41%|████      | 41/100 [00:43<01:01,  1.04s/it, loss=0.481, lr=0.002]Steps:  41%|████      | 41/100 [00:43<01:01,  1.04s/it, loss=0.564, lr=0.002]Steps:  42%|████▏     | 42/100 [00:43<01:00,  1.04s/it, loss=0.564, lr=0.002]Steps:  42%|████▏     | 42/100 [00:43<01:00,  1.04s/it, loss=0.582, lr=0.002]Steps:  42%|████▏     | 42/100 [00:44<01:00,  1.04s/it, loss=0.573, lr=0.002]Steps:  42%|████▏     | 42/100 [00:44<01:00,  1.04s/it, loss=0.435, lr=0.002]Steps:  42%|████▏     | 42/100 [00:44<01:00,  1.04s/it, loss=0.371, lr=0.002]Steps:  43%|████▎     | 43/100 [00:44<00:59,  1.04s/it, loss=0.371, lr=0.002]Steps:  43%|████▎     | 43/100 [00:44<00:59,  1.04s/it, loss=0.559, lr=0.002]Steps:  43%|████▎     | 43/100 [00:45<00:59,  1.04s/it, loss=0.55, lr=0.002] Steps:  43%|████▎     | 43/100 [00:45<00:59,  1.04s/it, loss=0.389, lr=0.002]Steps:  43%|████▎     | 43/100 [00:45<00:59,  1.04s/it, loss=0.569, lr=0.002]Steps:  44%|████▍     | 44/100 [00:45<00:58,  1.04s/it, loss=0.569, lr=0.002]Steps:  44%|████▍     | 44/100 [00:45<00:58,  1.04s/it, loss=0.444, lr=0.002]Steps:  44%|████▍     | 44/100 [00:46<00:58,  1.04s/it, loss=0.568, lr=0.002]Steps:  44%|████▍     | 44/100 [00:46<00:58,  1.04s/it, loss=0.638, lr=0.002]Steps:  44%|████▍     | 44/100 [00:46<00:58,  1.04s/it, loss=0.577, lr=0.002]Steps:  45%|████▌     | 45/100 [00:46<00:57,  1.04s/it, loss=0.577, lr=0.002]Steps:  45%|████▌     | 45/100 [00:46<00:57,  1.04s/it, loss=0.568, lr=0.002]Steps:  45%|████▌     | 45/100 [00:47<00:57,  1.04s/it, loss=0.453, lr=0.002]Steps:  45%|████▌     | 45/100 [00:47<00:57,  1.04s/it, loss=0.375, lr=0.002]Steps:  45%|████▌     | 45/100 [00:47<00:57,  1.04s/it, loss=0.567, lr=0.002]Steps:  46%|████▌     | 46/100 [00:47<00:56,  1.04s/it, loss=0.567, lr=0.002]Steps:  46%|████▌     | 46/100 [00:47<00:56,  1.04s/it, loss=0.572, lr=0.002]Steps:  46%|████▌     | 46/100 [00:48<00:56,  1.04s/it, loss=0.457, lr=0.002]Steps:  46%|████▌     | 46/100 [00:48<00:56,  1.04s/it, loss=0.43, lr=0.002] Steps:  46%|████▌     | 46/100 [00:48<00:56,  1.04s/it, loss=0.547, lr=0.002]Steps:  47%|████▋     | 47/100 [00:48<00:55,  1.04s/it, loss=0.547, lr=0.002]Steps:  47%|████▋     | 47/100 [00:48<00:55,  1.04s/it, loss=0.526, lr=0.002]Steps:  47%|████▋     | 47/100 [00:49<00:55,  1.04s/it, loss=0.45, lr=0.002] Steps:  47%|████▋     | 47/100 [00:49<00:55,  1.04s/it, loss=0.407, lr=0.002]Steps:  47%|████▋     | 47/100 [00:49<00:55,  1.04s/it, loss=0.588, lr=0.002]Steps:  48%|████▊     | 48/100 [00:50<00:54,  1.04s/it, loss=0.588, lr=0.002]Steps:  48%|████▊     | 48/100 [00:50<00:54,  1.04s/it, loss=0.561, lr=0.002]Steps:  48%|████▊     | 48/100 [00:50<00:54,  1.04s/it, loss=0.379, lr=0.002]Steps:  48%|████▊     | 48/100 [00:50<00:54,  1.04s/it, loss=0.569, lr=0.002]Steps:  48%|████▊     | 48/100 [00:50<00:54,  1.04s/it, loss=0.574, lr=0.002]Steps:  49%|████▉     | 49/100 [00:51<00:53,  1.04s/it, loss=0.574, lr=0.002]Steps:  49%|████▉     | 49/100 [00:51<00:53,  1.04s/it, loss=0.566, lr=0.002]Steps:  49%|████▉     | 49/100 [00:51<00:53,  1.04s/it, loss=0.525, lr=0.002]Steps:  49%|████▉     | 49/100 [00:51<00:53,  1.04s/it, loss=0.44, lr=0.002] Steps:  49%|████▉     | 49/100 [00:51<00:53,  1.04s/it, loss=0.565, lr=0.002]Steps:  50%|█████     | 50/100 [00:52<00:51,  1.03s/it, loss=0.565, lr=0.002]Steps:  50%|█████     | 50/100 [00:52<00:51,  1.03s/it, loss=0.408, lr=0.002]Steps:  50%|█████     | 50/100 [00:52<00:51,  1.03s/it, loss=0.381, lr=0.002]Steps:  50%|█████     | 50/100 [00:52<00:51,  1.03s/it, loss=0.456, lr=0.002]Steps:  50%|█████     | 50/100 [00:52<00:51,  1.03s/it, loss=0.572, lr=0.002]Steps:  51%|█████     | 51/100 [00:53<00:50,  1.04s/it, loss=0.572, lr=0.002]Steps:  51%|█████     | 51/100 [00:53<00:50,  1.04s/it, loss=0.391, lr=0.002]Steps:  51%|█████     | 51/100 [00:53<00:50,  1.04s/it, loss=0.562, lr=0.002]Steps:  51%|█████     | 51/100 [00:53<00:50,  1.04s/it, loss=0.398, lr=0.002]Steps:  51%|█████     | 51/100 [00:53<00:50,  1.04s/it, loss=0.563, lr=0.002]Steps:  52%|█████▏    | 52/100 [00:54<00:49,  1.04s/it, loss=0.563, lr=0.002]Steps:  52%|█████▏    | 52/100 [00:54<00:49,  1.04s/it, loss=0.453, lr=0.002]Steps:  52%|█████▏    | 52/100 [00:54<00:49,  1.04s/it, loss=0.546, lr=0.002]Steps:  52%|█████▏    | 52/100 [00:54<00:49,  1.04s/it, loss=0.436, lr=0.002]Steps:  52%|█████▏    | 52/100 [00:54<00:49,  1.04s/it, loss=0.585, lr=0.002]Steps:  53%|█████▎    | 53/100 [00:55<00:48,  1.04s/it, loss=0.585, lr=0.002]Steps:  53%|█████▎    | 53/100 [00:55<00:48,  1.04s/it, loss=0.395, lr=0.002]Steps:  53%|█████▎    | 53/100 [00:55<00:48,  1.04s/it, loss=0.398, lr=0.002]Steps:  53%|█████▎    | 53/100 [00:55<00:48,  1.04s/it, loss=0.39, lr=0.002] Steps:  53%|█████▎    | 53/100 [00:55<00:48,  1.04s/it, loss=0.445, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:56<00:47,  1.04s/it, loss=0.445, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:56<00:47,  1.04s/it, loss=0.579, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:56<00:47,  1.04s/it, loss=0.549, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:56<00:47,  1.04s/it, loss=0.574, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:57<00:47,  1.04s/it, loss=0.485, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:57<00:46,  1.04s/it, loss=0.485, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:57<00:46,  1.04s/it, loss=0.566, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:57<00:46,  1.04s/it, loss=0.578, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:57<00:46,  1.04s/it, loss=0.386, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:58<00:46,  1.04s/it, loss=0.555, lr=0.002]Steps:  56%|█████▌    | 56/100 [00:58<00:45,  1.04s/it, loss=0.555, lr=0.002]Steps:  56%|█████▌    | 56/100 [00:58<00:45,  1.04s/it, loss=0.558, lr=0.002]Steps:  56%|█████▌    | 56/100 [00:58<00:45,  1.04s/it, loss=0.391, lr=0.002]Steps:  56%|█████▌    | 56/100 [00:58<00:45,  1.04s/it, loss=0.566, lr=0.002]Steps:  56%|█████▌    | 56/100 [00:59<00:45,  1.04s/it, loss=0.571, lr=0.002]Steps:  57%|█████▋    | 57/100 [00:59<00:44,  1.04s/it, loss=0.571, lr=0.002]Steps:  57%|█████▋    | 57/100 [00:59<00:44,  1.04s/it, loss=0.542, lr=0.002]Steps:  57%|█████▋    | 57/100 [00:59<00:44,  1.04s/it, loss=0.541, lr=0.002]Steps:  57%|█████▋    | 57/100 [00:59<00:44,  1.04s/it, loss=0.561, lr=0.002]Steps:  57%|█████▋    | 57/100 [01:00<00:44,  1.04s/it, loss=0.584, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:00<00:43,  1.04s/it, loss=0.584, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:00<00:43,  1.04s/it, loss=0.394, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:00<00:43,  1.04s/it, loss=0.571, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:00<00:43,  1.04s/it, loss=0.511, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:01<00:43,  1.04s/it, loss=0.427, lr=0.002]Steps:  59%|█████▉    | 59/100 [01:01<00:42,  1.04s/it, loss=0.427, lr=0.002]Steps:  59%|█████▉    | 59/100 [01:01<00:42,  1.04s/it, loss=0.553, lr=0.002]Steps:  59%|█████▉    | 59/100 [01:01<00:42,  1.04s/it, loss=0.508, lr=0.002]Steps:  59%|█████▉    | 59/100 [01:01<00:42,  1.04s/it, loss=0.385, lr=0.002]Steps:  59%|█████▉    | 59/100 [01:02<00:42,  1.04s/it, loss=0.576, lr=0.002]Steps:  60%|██████    | 60/100 [01:02<00:41,  1.04s/it, loss=0.576, lr=0.002]Steps:  60%|██████    | 60/100 [01:02<00:41,  1.04s/it, loss=0.404, lr=0.002]Steps:  60%|██████    | 60/100 [01:02<00:41,  1.04s/it, loss=0.573, lr=0.002]Steps:  60%|██████    | 60/100 [01:03<00:41,  1.04s/it, loss=0.576, lr=0.002]Steps:  60%|██████    | 60/100 [01:03<00:41,  1.04s/it, loss=0.575, lr=0.002]Steps:  61%|██████    | 61/100 [01:03<00:40,  1.04s/it, loss=0.575, lr=0.002]Steps:  61%|██████    | 61/100 [01:03<00:40,  1.04s/it, loss=0.797, lr=0.002]Steps:  61%|██████    | 61/100 [01:03<00:40,  1.04s/it, loss=0.57, lr=0.002] Steps:  61%|██████    | 61/100 [01:04<00:40,  1.04s/it, loss=0.532, lr=0.002]Steps:  61%|██████    | 61/100 [01:04<00:40,  1.04s/it, loss=0.464, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:04<00:39,  1.04s/it, loss=0.464, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:04<00:39,  1.04s/it, loss=0.385, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:04<00:39,  1.04s/it, loss=0.566, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:05<00:39,  1.04s/it, loss=0.576, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:05<00:39,  1.04s/it, loss=0.569, lr=0.002]Steps:  63%|██████▎   | 63/100 [01:05<00:38,  1.04s/it, loss=0.569, lr=0.002]Steps:  63%|██████▎   | 63/100 [01:05<00:38,  1.04s/it, loss=0.38, lr=0.002] Steps:  63%|██████▎   | 63/100 [01:05<00:38,  1.04s/it, loss=0.384, lr=0.002]Steps:  63%|██████▎   | 63/100 [01:06<00:38,  1.04s/it, loss=0.573, lr=0.002]Steps:  63%|██████▎   | 63/100 [01:06<00:38,  1.04s/it, loss=0.575, lr=0.002]Steps:  64%|██████▍   | 64/100 [01:06<00:37,  1.04s/it, loss=0.575, lr=0.002]Steps:  64%|██████▍   | 64/100 [01:06<00:37,  1.04s/it, loss=0.418, lr=0.002]Steps:  64%|██████▍   | 64/100 [01:06<00:37,  1.04s/it, loss=0.539, lr=0.002]Steps:  64%|██████▍   | 64/100 [01:07<00:37,  1.04s/it, loss=0.38, lr=0.002] Steps:  64%|██████▍   | 64/100 [01:07<00:37,  1.04s/it, loss=0.393, lr=0.002]Steps:  65%|██████▌   | 65/100 [01:07<00:36,  1.04s/it, loss=0.393, lr=0.002]Steps:  65%|██████▌   | 65/100 [01:07<00:36,  1.04s/it, loss=0.54, lr=0.002] Steps:  65%|██████▌   | 65/100 [01:07<00:36,  1.04s/it, loss=0.549, lr=0.002]Steps:  65%|██████▌   | 65/100 [01:08<00:36,  1.04s/it, loss=0.393, lr=0.002]Steps:  65%|██████▌   | 65/100 [01:08<00:36,  1.04s/it, loss=0.399, lr=0.002]Steps:  66%|██████▌   | 66/100 [01:08<00:35,  1.04s/it, loss=0.399, lr=0.002]Steps:  66%|██████▌   | 66/100 [01:08<00:35,  1.04s/it, loss=0.576, lr=0.002]Steps:  66%|██████▌   | 66/100 [01:09<00:35,  1.04s/it, loss=0.387, lr=0.002]Steps:  66%|██████▌   | 66/100 [01:09<00:35,  1.04s/it, loss=0.424, lr=0.002]Steps:  66%|██████▌   | 66/100 [01:09<00:35,  1.04s/it, loss=0.565, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:09<00:34,  1.04s/it, loss=0.565, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:09<00:34,  1.04s/it, loss=0.578, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:10<00:34,  1.04s/it, loss=0.377, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:10<00:34,  1.04s/it, loss=0.574, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:10<00:34,  1.04s/it, loss=0.492, lr=0.002]Steps:  68%|██████▊   | 68/100 [01:10<00:33,  1.04s/it, loss=0.492, lr=0.002]Steps:  68%|██████▊   | 68/100 [01:10<00:33,  1.04s/it, loss=0.568, lr=0.002]Steps:  68%|██████▊   | 68/100 [01:11<00:33,  1.04s/it, loss=0.561, lr=0.002]Steps:  68%|██████▊   | 68/100 [01:11<00:33,  1.04s/it, loss=0.404, lr=0.002]Steps:  68%|██████▊   | 68/100 [01:11<00:33,  1.04s/it, loss=0.535, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:11<00:32,  1.04s/it, loss=0.535, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:11<00:32,  1.04s/it, loss=0.401, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:12<00:32,  1.04s/it, loss=0.435, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:12<00:32,  1.04s/it, loss=0.566, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:12<00:32,  1.04s/it, loss=0.385, lr=0.002]Steps:  70%|███████   | 70/100 [01:12<00:31,  1.04s/it, loss=0.385, lr=0.002]Steps:  70%|███████   | 70/100 [01:12<00:31,  1.04s/it, loss=0.385, lr=0.002]Steps:  70%|███████   | 70/100 [01:13<00:31,  1.04s/it, loss=0.477, lr=0.002]Steps:  70%|███████   | 70/100 [01:13<00:31,  1.04s/it, loss=0.53, lr=0.002] Steps:  70%|███████   | 70/100 [01:13<00:31,  1.04s/it, loss=0.473, lr=0.002]Steps:  71%|███████   | 71/100 [01:13<00:30,  1.04s/it, loss=0.473, lr=0.002]Steps:  71%|███████   | 71/100 [01:13<00:30,  1.04s/it, loss=0.54, lr=0.002] Steps:  71%|███████   | 71/100 [01:14<00:30,  1.04s/it, loss=0.561, lr=0.002]Steps:  71%|███████   | 71/100 [01:14<00:30,  1.04s/it, loss=0.573, lr=0.002]Steps:  71%|███████   | 71/100 [01:14<00:30,  1.04s/it, loss=0.549, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:15<00:29,  1.04s/it, loss=0.549, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:15<00:29,  1.04s/it, loss=0.445, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:15<00:29,  1.04s/it, loss=0.573, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:15<00:29,  1.04s/it, loss=0.482, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:15<00:29,  1.04s/it, loss=0.577, lr=0.002]Steps:  73%|███████▎  | 73/100 [01:16<00:28,  1.04s/it, loss=0.577, lr=0.002]Steps:  73%|███████▎  | 73/100 [01:16<00:28,  1.04s/it, loss=0.489, lr=0.002]Steps:  73%|███████▎  | 73/100 [01:16<00:28,  1.04s/it, loss=0.541, lr=0.002]Steps:  73%|███████▎  | 73/100 [01:16<00:28,  1.04s/it, loss=0.573, lr=0.002]Steps:  73%|███████▎  | 73/100 [01:16<00:28,  1.04s/it, loss=0.567, lr=0.002]Steps:  74%|███████▍  | 74/100 [01:17<00:27,  1.04s/it, loss=0.567, lr=0.002]Steps:  74%|███████▍  | 74/100 [01:17<00:27,  1.04s/it, loss=0.585, lr=0.002]Steps:  74%|███████▍  | 74/100 [01:17<00:27,  1.04s/it, loss=0.567, lr=0.002]Steps:  74%|███████▍  | 74/100 [01:17<00:27,  1.04s/it, loss=0.555, lr=0.002]Steps:  74%|███████▍  | 74/100 [01:17<00:27,  1.04s/it, loss=0.584, lr=0.002]Steps:  75%|███████▌  | 75/100 [01:18<00:25,  1.03s/it, loss=0.584, lr=0.002]Steps:  75%|███████▌  | 75/100 [01:18<00:25,  1.03s/it, loss=0.392, lr=0.002]Steps:  75%|███████▌  | 75/100 [01:18<00:25,  1.03s/it, loss=0.572, lr=0.002]Steps:  75%|███████▌  | 75/100 [01:18<00:25,  1.03s/it, loss=0.45, lr=0.002] Steps:  75%|███████▌  | 75/100 [01:18<00:25,  1.03s/it, loss=0.538, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:19<00:24,  1.04s/it, loss=0.538, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:19<00:24,  1.04s/it, loss=0.366, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:19<00:24,  1.04s/it, loss=0.548, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:19<00:24,  1.04s/it, loss=0.566, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:19<00:24,  1.04s/it, loss=0.573, lr=0.002]Steps:  77%|███████▋  | 77/100 [01:20<00:23,  1.04s/it, loss=0.573, lr=0.002]Steps:  77%|███████▋  | 77/100 [01:20<00:23,  1.04s/it, loss=0.43, lr=0.002] Steps:  77%|███████▋  | 77/100 [01:20<00:23,  1.04s/it, loss=0.544, lr=0.002]Steps:  77%|███████▋  | 77/100 [01:20<00:23,  1.04s/it, loss=0.49, lr=0.002] Steps:  77%|███████▋  | 77/100 [01:21<00:23,  1.04s/it, loss=0.377, lr=0.002]Steps:  78%|███████▊  | 78/100 [01:21<00:23,  1.07s/it, loss=0.377, lr=0.002]Steps:  78%|███████▊  | 78/100 [01:21<00:23,  1.07s/it, loss=0.496, lr=0.002]Steps:  78%|███████▊  | 78/100 [01:21<00:23,  1.07s/it, loss=0.542, lr=0.002]Steps:  78%|███████▊  | 78/100 [01:21<00:23,  1.07s/it, loss=0.539, lr=0.002]Steps:  78%|███████▊  | 78/100 [01:22<00:23,  1.07s/it, loss=0.464, lr=0.002]Steps:  79%|███████▉  | 79/100 [01:22<00:23,  1.12s/it, loss=0.464, lr=0.002]Steps:  79%|███████▉  | 79/100 [01:22<00:23,  1.12s/it, loss=0.391, lr=0.002]Steps:  79%|███████▉  | 79/100 [01:22<00:23,  1.12s/it, loss=0.537, lr=0.002]Steps:  79%|███████▉  | 79/100 [01:23<00:23,  1.12s/it, loss=0.436, lr=0.002]Steps:  79%|███████▉  | 79/100 [01:23<00:23,  1.12s/it, loss=0.464, lr=0.002]Steps:  80%|████████  | 80/100 [01:23<00:23,  1.16s/it, loss=0.464, lr=0.002]Steps:  80%|████████  | 80/100 [01:23<00:23,  1.16s/it, loss=0.39, lr=0.002] Steps:  80%|████████  | 80/100 [01:24<00:23,  1.16s/it, loss=0.435, lr=0.002]Steps:  80%|████████  | 80/100 [01:24<00:23,  1.16s/it, loss=0.567, lr=0.002]Steps:  80%|████████  | 80/100 [01:24<00:23,  1.16s/it, loss=0.403, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:22,  1.18s/it, loss=0.403, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:22,  1.18s/it, loss=0.504, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:22,  1.18s/it, loss=0.576, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:22,  1.18s/it, loss=0.568, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:22,  1.18s/it, loss=0.498, lr=0.002]Steps:  82%|████████▏ | 82/100 [01:26<00:21,  1.20s/it, loss=0.498, lr=0.002]Steps:  82%|████████▏ | 82/100 [01:26<00:21,  1.20s/it, loss=0.571, lr=0.002]Steps:  82%|████████▏ | 82/100 [01:26<00:21,  1.20s/it, loss=0.541, lr=0.002]Steps:  82%|████████▏ | 82/100 [01:26<00:21,  1.20s/it, loss=0.574, lr=0.002]Steps:  82%|████████▏ | 82/100 [01:27<00:21,  1.20s/it, loss=0.415, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:27<00:20,  1.21s/it, loss=0.415, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:27<00:20,  1.21s/it, loss=0.398, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:27<00:20,  1.21s/it, loss=0.561, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:28<00:20,  1.21s/it, loss=0.458, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:28<00:20,  1.21s/it, loss=0.444, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:28<00:19,  1.22s/it, loss=0.444, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:28<00:19,  1.22s/it, loss=0.436, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:29<00:19,  1.22s/it, loss=0.567, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:29<00:19,  1.22s/it, loss=0.411, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:29<00:19,  1.22s/it, loss=0.402, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:30<00:18,  1.22s/it, loss=0.402, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:30<00:18,  1.22s/it, loss=0.388, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:30<00:18,  1.22s/it, loss=0.388, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:30<00:18,  1.22s/it, loss=0.567, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:30<00:18,  1.22s/it, loss=0.478, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:31<00:17,  1.23s/it, loss=0.478, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:31<00:17,  1.23s/it, loss=0.561, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:31<00:17,  1.23s/it, loss=0.391, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:31<00:17,  1.23s/it, loss=0.573, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:32<00:17,  1.23s/it, loss=0.565, lr=0.002]Steps:  87%|████████▋ | 87/100 [01:32<00:16,  1.23s/it, loss=0.565, lr=0.002]Steps:  87%|████████▋ | 87/100 [01:32<00:16,  1.23s/it, loss=0.597, lr=0.002]Steps:  87%|████████▋ | 87/100 [01:32<00:16,  1.23s/it, loss=0.568, lr=0.002]Steps:  87%|████████▋ | 87/100 [01:33<00:16,  1.23s/it, loss=0.415, lr=0.002]Steps:  87%|████████▋ | 87/100 [01:33<00:16,  1.23s/it, loss=0.394, lr=0.002]Steps:  88%|████████▊ | 88/100 [01:33<00:14,  1.23s/it, loss=0.394, lr=0.002]Steps:  88%|████████▊ | 88/100 [01:33<00:14,  1.23s/it, loss=0.419, lr=0.002]Steps:  88%|████████▊ | 88/100 [01:34<00:14,  1.23s/it, loss=0.582, lr=0.002]Steps:  88%|████████▊ | 88/100 [01:34<00:14,  1.23s/it, loss=0.511, lr=0.002]Steps:  88%|████████▊ | 88/100 [01:34<00:14,  1.23s/it, loss=0.561, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:34<00:13,  1.24s/it, loss=0.561, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:34<00:13,  1.24s/it, loss=0.561, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:35<00:13,  1.24s/it, loss=0.381, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:35<00:13,  1.24s/it, loss=0.452, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:35<00:13,  1.24s/it, loss=0.425, lr=0.002]Steps:  90%|█████████ | 90/100 [01:36<00:12,  1.24s/it, loss=0.425, lr=0.002]Steps:  90%|█████████ | 90/100 [01:36<00:12,  1.24s/it, loss=0.383, lr=0.002]Steps:  90%|█████████ | 90/100 [01:36<00:12,  1.24s/it, loss=0.557, lr=0.002]Steps:  90%|█████████ | 90/100 [01:36<00:12,  1.24s/it, loss=0.553, lr=0.002]Steps:  90%|█████████ | 90/100 [01:37<00:12,  1.24s/it, loss=0.609, lr=0.002]Steps:  91%|█████████ | 91/100 [01:37<00:11,  1.24s/it, loss=0.609, lr=0.002]Steps:  91%|█████████ | 91/100 [01:37<00:11,  1.24s/it, loss=0.546, lr=0.002]Steps:  91%|█████████ | 91/100 [01:37<00:11,  1.24s/it, loss=0.525, lr=0.002]Steps:  91%|█████████ | 91/100 [01:38<00:11,  1.24s/it, loss=0.426, lr=0.002]Steps:  91%|█████████ | 91/100 [01:38<00:11,  1.24s/it, loss=0.393, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:38<00:09,  1.24s/it, loss=0.393, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:38<00:09,  1.24s/it, loss=0.466, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:38<00:09,  1.24s/it, loss=0.557, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:39<00:09,  1.24s/it, loss=0.407, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:39<00:09,  1.24s/it, loss=0.581, lr=0.002]Steps:  93%|█████████▎| 93/100 [01:39<00:08,  1.24s/it, loss=0.581, lr=0.002]Steps:  93%|█████████▎| 93/100 [01:39<00:08,  1.24s/it, loss=0.58, lr=0.002] Steps:  93%|█████████▎| 93/100 [01:40<00:08,  1.24s/it, loss=0.569, lr=0.002]Steps:  93%|█████████▎| 93/100 [01:40<00:08,  1.24s/it, loss=0.505, lr=0.002]Steps:  93%|█████████▎| 93/100 [01:40<00:08,  1.24s/it, loss=0.564, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:41<00:07,  1.24s/it, loss=0.564, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:41<00:07,  1.24s/it, loss=0.558, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:41<00:07,  1.24s/it, loss=0.464, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:41<00:07,  1.24s/it, loss=0.391, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:42<00:07,  1.24s/it, loss=0.361, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:42<00:06,  1.24s/it, loss=0.361, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:42<00:06,  1.24s/it, loss=0.437, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:42<00:06,  1.24s/it, loss=0.475, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:43<00:06,  1.24s/it, loss=0.388, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:43<00:06,  1.24s/it, loss=0.554, lr=0.002]Steps:  96%|█████████▌| 96/100 [01:43<00:04,  1.24s/it, loss=0.554, lr=0.002]Steps:  96%|█████████▌| 96/100 [01:43<00:04,  1.24s/it, loss=0.573, lr=0.002]Steps:  96%|█████████▌| 96/100 [01:43<00:04,  1.24s/it, loss=0.575, lr=0.002]Steps:  96%|█████████▌| 96/100 [01:44<00:04,  1.24s/it, loss=0.432, lr=0.002]Steps:  96%|█████████▌| 96/100 [01:44<00:04,  1.24s/it, loss=0.391, lr=0.002]Steps:  97%|█████████▋| 97/100 [01:44<00:03,  1.24s/it, loss=0.391, lr=0.002]Steps:  97%|█████████▋| 97/100 [01:44<00:03,  1.24s/it, loss=0.382, lr=0.002]Steps:  97%|█████████▋| 97/100 [01:45<00:03,  1.24s/it, loss=0.38, lr=0.002] Steps:  97%|█████████▋| 97/100 [01:45<00:03,  1.24s/it, loss=0.383, lr=0.002]Steps:  97%|█████████▋| 97/100 [01:45<00:03,  1.24s/it, loss=0.385, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:46<00:02,  1.24s/it, loss=0.385, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:46<00:02,  1.24s/it, loss=0.568, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:46<00:02,  1.24s/it, loss=0.477, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:46<00:02,  1.24s/it, loss=0.428, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:47<00:02,  1.24s/it, loss=0.575, lr=0.002]Steps:  99%|█████████▉| 99/100 [01:47<00:01,  1.24s/it, loss=0.575, lr=0.002]Steps:  99%|█████████▉| 99/100 [01:47<00:01,  1.24s/it, loss=0.562, lr=0.002]Steps:  99%|█████████▉| 99/100 [01:47<00:01,  1.24s/it, loss=0.566, lr=0.002]Steps:  99%|█████████▉| 99/100 [01:47<00:01,  1.24s/it, loss=0.569, lr=0.002]Steps:  99%|█████████▉| 99/100 [01:48<00:01,  1.24s/it, loss=0.501, lr=0.002]Steps: 100%|██████████| 100/100 [01:48<00:00,  1.23s/it, loss=0.501, lr=0.002]Steps: 100%|██████████| 100/100 [01:48<00:00,  1.23s/it, loss=0.798, lr=0.002]Steps: 100%|██████████| 100/100 [01:48<00:00,  1.09s/it, loss=0.798, lr=0.002]
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'CLIPTokenizer'. 
The class this function is called from is 'MultiTokenCLIPTokenizer'.
{'requires_safety_checker'} was not found in config. Values will be initialized to default values.
The config attributes {'dropout': 0.0} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.
{'mid_block_scale_factor', 'upcast_attention', 'use_linear_projection', 'center_input_sample', 'downsample_padding', 'dual_cross_attention', 'act_fn', 'only_cross_attention', 'norm_num_groups', 'norm_eps', 'flip_sin_to_cos', 'num_class_embeds'} was not found in config. Values will be initialized to default values.
number of placeholder tokens are: 3
[49406, 49407]
[49406, 49408, 49409, 49410, 49407]
init_context =  torch.Size([3, 77, 768])
input_tensor 是张量类型
self.context torch.Size([2, 77, 768])
latent_cur =  torch.Size([4, 64, 64])
noise_loss_list[0].shape =  torch.Size([1, 4, 64, 64])
noist_list.shape =  torch.Size([50, 1, 4, 64, 64])
  0%|          | 0/50 [00:00<?, ?it/s]  0%|          | 0/50 [00:00<?, ?it/s]
latent =  torch.Size([2, 4, 64, 64])
Traceback (most recent call last):
  File "main.py", line 901, in <module>
    gen_image.gen_image(
  File "/home/dingkaixin/srtp_sd-2/gen_image.py", line 102, in gen_image
    latents = inversion.backward_diffusion_ptp(
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/dingkaixin/srtp_sd-2/ptp_inversion.py", line 737, in backward_diffusion_ptp
    latents = ptp_utils.diffusion_step_direct_inversion(model, controller, latents, context, t, guidance_scale, noise_loss=noise_loss_list[i], low_resource=False, add_offset=True)
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/dingkaixin/srtp_sd-2/ptp_utils.py", line 86, in diffusion_step_direct_inversion
    noise_pred = model.unet(latents_input, t, encoder_hidden_states=context)["sample"]
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/diffusers/models/unet_2d_condition.py", line 381, in forward
    sample, res_samples = downsample_block(
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/diffusers/models/unet_2d_blocks.py", line 612, in forward
    hidden_states = attn(hidden_states, encoder_hidden_states=encoder_hidden_states).sample
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/diffusers/models/attention.py", line 217, in forward
    hidden_states = block(hidden_states, context=encoder_hidden_states, timestep=timestep)
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/diffusers/models/attention.py", line 502, in forward
    hidden_states = self.attn2(norm_hidden_states, context=context) + hidden_states
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dingkaixin/srtp_sd-2/ptp_utils.py", line 226, in forward
    sim = torch.einsum("b i d, b j d -> b i j", q, k) * self.scale
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/functional.py", line 327, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
RuntimeError: einsum(): operands do not broadcast with remapped shapes [original->remapped]: [16, 4096, 40]->[16, 4096, 1, 40] [32, 77, 40]->[32, 1, 77, 40]
Traceback (most recent call last):
  File "/home/dingkaixin/.conda/envs/vct/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py", line 45, in main
    args.func(args)
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/accelerate/commands/launch.py", line 1104, in launch_command
    simple_launcher(args)
  File "/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/accelerate/commands/launch.py", line 567, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/dingkaixin/.conda/envs/vct/bin/python', 'main.py', '--concept_image_dir=./examples/jieni/', '--content_image_dir=./examples/lion/', '--initializer_token=pokemon', '--pretrained_model_name_or_path=/home/dingkaixin/s', '--output_image_path=./output_images/12-6-5', '--cross_attention_injection_ratio=0.2', '--self_attention_injection_ratio=0.9', '--guidance_scale_train_src=7.5', '--guidance_scale_train_ref=7.5', '--guidance_scale_gen=7.5', '--only_save_embeds', '--use_l1', '--max_train_steps=100', '--use_ref_cfg', '--no_controller', '--use_direct_inversion']' returned non-zero exit status 1.
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'CLIPTokenizer'. 
The class this function is called from is 'MultiTokenCLIPTokenizer'.
/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
  warnings.warn(
The config attributes {'dropout': 0.0} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.
/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:101: FutureWarning: The configuration file of this scheduler: DDIMScheduler {
  "_class_name": "DDIMScheduler",
  "_diffusers_version": "0.10.1",
  "beta_end": 0.012,
  "beta_schedule": "scaled_linear",
  "beta_start": 0.00085,
  "clip_sample": false,
  "num_train_timesteps": 1000,
  "prediction_type": "epsilon",
  "set_alpha_to_one": false,
  "steps_offset": 0,
  "trained_betas": null
}
 is outdated. `steps_offset` should be set to 1 instead of 0. Please make sure to update the config accordingly as leaving `steps_offset` might led to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json` file
  deprecate("steps_offset!=1", "1.0.0", deprecation_message, standard_warn=False)
use ref cfg: True
    Using ref classifier free guidance...
    guidance_scale_train_ref: 7.5
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:02, 19.28it/s] 10%|█         | 5/50 [00:00<00:02, 21.06it/s] 16%|█▌        | 8/50 [00:00<00:01, 21.50it/s] 22%|██▏       | 11/50 [00:00<00:01, 21.67it/s] 28%|██▊       | 14/50 [00:00<00:01, 21.73it/s] 34%|███▍      | 17/50 [00:00<00:01, 21.79it/s] 40%|████      | 20/50 [00:00<00:01, 21.81it/s] 46%|████▌     | 23/50 [00:01<00:01, 21.84it/s] 52%|█████▏    | 26/50 [00:01<00:01, 21.85it/s] 58%|█████▊    | 29/50 [00:01<00:00, 21.87it/s] 64%|██████▍   | 32/50 [00:01<00:00, 21.88it/s] 70%|███████   | 35/50 [00:01<00:00, 21.87it/s] 76%|███████▌  | 38/50 [00:01<00:00, 21.87it/s] 82%|████████▏ | 41/50 [00:01<00:00, 21.82it/s] 88%|████████▊ | 44/50 [00:02<00:00, 21.86it/s] 94%|█████████▍| 47/50 [00:02<00:00, 21.86it/s]100%|██████████| 50/50 [00:02<00:00, 21.89it/s]100%|██████████| 50/50 [00:02<00:00, 21.77it/s]
  0%|          | 0/2500 [00:00<?, ?it/s]  0%|          | 0/2500 [00:00<?, ?it/s, loss=2.95e-8]  0%|          | 1/2500 [00:00<08:39,  4.81it/s, loss=2.95e-8]  2%|▏         | 50/2500 [00:00<08:29,  4.81it/s, loss=1.88e-6]  2%|▏         | 51/2500 [00:00<00:20, 121.38it/s, loss=1.88e-6]  4%|▍         | 100/2500 [00:00<00:19, 121.38it/s, loss=1.96e-6]  4%|▍         | 101/2500 [00:00<00:15, 154.75it/s, loss=1.96e-6]  6%|▌         | 150/2500 [00:00<00:15, 154.75it/s, loss=1.38e-6]  6%|▌         | 151/2500 [00:01<00:13, 169.88it/s, loss=1.38e-6]  8%|▊         | 200/2500 [00:01<00:13, 169.88it/s, loss=3.69e-6]  8%|▊         | 201/2500 [00:01<00:12, 178.11it/s, loss=3.69e-6] 10%|█         | 250/2500 [00:01<00:12, 178.11it/s, loss=3.01e-6] 10%|█         | 251/2500 [00:01<00:12, 183.20it/s, loss=3.01e-6] 12%|█▏        | 300/2500 [00:01<00:12, 183.20it/s, loss=9.11e-6] 12%|█▏        | 301/2500 [00:01<00:11, 186.00it/s, loss=9.11e-6] 14%|█▍        | 350/2500 [00:02<00:11, 186.00it/s, loss=8.3e-6]  14%|█▍        | 351/2500 [00:02<00:11, 187.71it/s, loss=8.3e-6] 16%|█▌        | 400/2500 [00:02<00:11, 187.71it/s, loss=1.88e-5] 16%|█▌        | 401/2500 [00:02<00:11, 188.98it/s, loss=1.88e-5] 18%|█▊        | 450/2500 [00:02<00:10, 188.98it/s, loss=1.96e-5] 18%|█▊        | 451/2500 [00:02<00:10, 189.93it/s, loss=1.96e-5] 20%|██        | 500/2500 [00:02<00:10, 189.93it/s, loss=2.69e-5] 20%|██        | 501/2500 [00:02<00:10, 190.48it/s, loss=2.69e-5] 22%|██▏       | 550/2500 [00:03<00:10, 190.48it/s, loss=4.36e-5] 22%|██▏       | 551/2500 [00:03<00:10, 191.06it/s, loss=4.36e-5] 24%|██▍       | 600/2500 [00:03<00:09, 191.06it/s, loss=3.62e-5] 24%|██▍       | 601/2500 [00:03<00:09, 191.51it/s, loss=3.62e-5] 26%|██▌       | 650/2500 [00:03<00:09, 191.51it/s, loss=7.93e-5] 26%|██▌       | 651/2500 [00:03<00:09, 191.84it/s, loss=7.93e-5] 28%|██▊       | 700/2500 [00:03<00:09, 191.84it/s, loss=5.12e-5] 28%|██▊       | 701/2500 [00:03<00:09, 192.04it/s, loss=5.12e-5] 30%|███       | 750/2500 [00:04<00:09, 192.04it/s, loss=7.39e-5] 30%|███       | 751/2500 [00:04<00:09, 191.99it/s, loss=7.39e-5] 32%|███▏      | 800/2500 [00:04<00:08, 191.99it/s, loss=4.78e-5] 32%|███▏      | 801/2500 [00:04<00:08, 191.60it/s, loss=4.78e-5] 34%|███▍      | 850/2500 [00:04<00:08, 191.60it/s, loss=7.4e-5]  34%|███▍      | 851/2500 [00:04<00:08, 191.79it/s, loss=7.4e-5] 36%|███▌      | 900/2500 [00:04<00:08, 191.79it/s, loss=0.000113] 36%|███▌      | 901/2500 [00:04<00:08, 191.93it/s, loss=0.000113] 38%|███▊      | 950/2500 [00:05<00:08, 191.93it/s, loss=8.47e-5]  38%|███▊      | 951/2500 [00:05<00:08, 191.85it/s, loss=8.47e-5] 40%|████      | 1000/2500 [00:05<00:07, 191.85it/s, loss=9.59e-5] 40%|████      | 1001/2500 [00:05<00:07, 191.85it/s, loss=9.59e-5] 42%|████▏     | 1050/2500 [00:05<00:07, 191.85it/s, loss=9.63e-5] 42%|████▏     | 1051/2500 [00:05<00:07, 191.65it/s, loss=9.63e-5] 44%|████▍     | 1100/2500 [00:05<00:07, 191.65it/s, loss=0.000102] 44%|████▍     | 1101/2500 [00:05<00:07, 191.66it/s, loss=0.000102] 46%|████▌     | 1150/2500 [00:06<00:07, 191.66it/s, loss=0.00011]  46%|████▌     | 1151/2500 [00:06<00:07, 191.77it/s, loss=0.00011] 48%|████▊     | 1200/2500 [00:06<00:06, 191.77it/s, loss=0.000116] 48%|████▊     | 1201/2500 [00:06<00:06, 191.68it/s, loss=0.000116] 50%|█████     | 1250/2500 [00:06<00:06, 191.68it/s, loss=0.000127] 50%|█████     | 1251/2500 [00:06<00:06, 191.57it/s, loss=0.000127] 52%|█████▏    | 1300/2500 [00:06<00:06, 191.57it/s, loss=0.000134] 52%|█████▏    | 1301/2500 [00:06<00:06, 191.48it/s, loss=0.000134] 54%|█████▍    | 1350/2500 [00:07<00:06, 191.48it/s, loss=0.000146] 54%|█████▍    | 1351/2500 [00:07<00:05, 191.59it/s, loss=0.000146] 56%|█████▌    | 1400/2500 [00:07<00:05, 191.59it/s, loss=0.000155] 56%|█████▌    | 1401/2500 [00:07<00:05, 191.58it/s, loss=0.000155] 58%|█████▊    | 1450/2500 [00:07<00:05, 191.58it/s, loss=0.000167] 58%|█████▊    | 1451/2500 [00:07<00:05, 191.57it/s, loss=0.000167] 60%|██████    | 1500/2500 [00:08<00:05, 191.57it/s, loss=0.000178] 60%|██████    | 1501/2500 [00:08<00:05, 191.47it/s, loss=0.000178] 62%|██████▏   | 1550/2500 [00:08<00:04, 191.47it/s, loss=0.00019]  62%|██████▏   | 1551/2500 [00:08<00:04, 191.41it/s, loss=0.00019] 64%|██████▍   | 1600/2500 [00:08<00:04, 191.41it/s, loss=0.000201] 64%|██████▍   | 1601/2500 [00:08<00:04, 191.27it/s, loss=0.000201] 66%|██████▌   | 1650/2500 [00:08<00:04, 191.27it/s, loss=0.000213] 66%|██████▌   | 1651/2500 [00:08<00:04, 191.28it/s, loss=0.000213] 68%|██████▊   | 1700/2500 [00:09<00:04, 191.28it/s, loss=0.000223] 68%|██████▊   | 1701/2500 [00:09<00:04, 191.18it/s, loss=0.000223] 70%|███████   | 1750/2500 [00:09<00:03, 191.18it/s, loss=0.000233] 70%|███████   | 1751/2500 [00:09<00:03, 191.18it/s, loss=0.000233] 72%|███████▏  | 1800/2500 [00:09<00:03, 191.18it/s, loss=0.000244] 72%|███████▏  | 1801/2500 [00:09<00:03, 191.19it/s, loss=0.000244] 74%|███████▍  | 1850/2500 [00:09<00:03, 191.19it/s, loss=0.000257] 74%|███████▍  | 1851/2500 [00:09<00:03, 191.29it/s, loss=0.000257] 76%|███████▌  | 1900/2500 [00:10<00:03, 191.29it/s, loss=0.000271] 76%|███████▌  | 1901/2500 [00:10<00:03, 191.02it/s, loss=0.000271] 78%|███████▊  | 1950/2500 [00:10<00:02, 191.02it/s, loss=0.000286] 78%|███████▊  | 1951/2500 [00:10<00:02, 191.15it/s, loss=0.000286] 80%|████████  | 2000/2500 [00:10<00:02, 191.15it/s, loss=0.000302] 80%|████████  | 2001/2500 [00:10<00:02, 191.17it/s, loss=0.000302] 82%|████████▏ | 2050/2500 [00:10<00:02, 191.17it/s, loss=0.000319] 82%|████████▏ | 2051/2500 [00:10<00:02, 190.96it/s, loss=0.000319] 84%|████████▍ | 2100/2500 [00:11<00:02, 190.96it/s, loss=0.000336] 84%|████████▍ | 2101/2500 [00:11<00:02, 190.82it/s, loss=0.000336] 86%|████████▌ | 2150/2500 [00:11<00:01, 190.82it/s, loss=0.000355] 86%|████████▌ | 2151/2500 [00:11<00:01, 190.98it/s, loss=0.000355] 88%|████████▊ | 2200/2500 [00:11<00:01, 190.98it/s, loss=0.000377] 88%|████████▊ | 2201/2500 [00:11<00:01, 190.89it/s, loss=0.000377] 90%|█████████ | 2250/2500 [00:11<00:01, 190.89it/s, loss=0.000404] 90%|█████████ | 2251/2500 [00:11<00:01, 190.83it/s, loss=0.000404] 92%|█████████▏| 2300/2500 [00:12<00:01, 190.83it/s, loss=0.000442] 92%|█████████▏| 2301/2500 [00:12<00:01, 190.77it/s, loss=0.000442] 94%|█████████▍| 2350/2500 [00:12<00:00, 190.77it/s, loss=0.000504] 94%|█████████▍| 2351/2500 [00:12<00:00, 190.88it/s, loss=0.000504] 96%|█████████▌| 2400/2500 [00:12<00:00, 190.88it/s, loss=0.000752] 96%|█████████▌| 2401/2500 [00:12<00:00, 190.81it/s, loss=0.000752] 98%|█████████▊| 2450/2500 [00:13<00:00, 190.81it/s, loss=0.000731] 98%|█████████▊| 2451/2500 [00:13<00:00, 190.79it/s, loss=0.000731]100%|██████████| 2500/2500 [00:13<00:00, 191.48it/s, loss=0.000731]
/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/accelerate/accelerator.py:321: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
12/07/2023 17:37:28 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Mixed precision type: no

The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'CLIPTokenizer'. 
The class this function is called from is 'MultiTokenCLIPTokenizer'.
The config attributes {'set_alpha_to_one': False, 'skip_prk_steps': True, 'steps_offset': 1} were passed to DDPMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.
{'clip_sample', 'variance_type'} was not found in config. Values will be initialized to default values.
The config attributes {'dropout': 0.0} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.
{'norm_num_groups', 'flip_sin_to_cos', 'use_linear_projection', 'downsample_padding', 'center_input_sample', 'only_cross_attention', 'mid_block_scale_factor', 'num_class_embeds', 'dual_cross_attention', 'upcast_attention', 'norm_eps', 'act_fn'} was not found in config. Values will be initialized to default values.
12/07/2023 17:41:52 - INFO - __main__ - ***** Running training *****
12/07/2023 17:41:52 - INFO - __main__ -   Num examples = 100
12/07/2023 17:41:52 - INFO - __main__ -   Num Epochs = 4
12/07/2023 17:41:52 - INFO - __main__ -   Instantaneous batch size per device = 1
12/07/2023 17:41:52 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
12/07/2023 17:41:52 - INFO - __main__ -   Gradient Accumulation steps = 4
12/07/2023 17:41:52 - INFO - __main__ -   Total optimization steps = 100
number of placeholder tokens are: 3
  0%|          | 0/100 [00:00<?, ?it/s]Steps:   0%|          | 0/100 [00:00<?, ?it/s]/home/dingkaixin/.conda/envs/vct/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
main.py:802: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  src_pred = unet(noisy_latents, timesteps, src_embedding_list[timesteps // 20]).sample
Steps:   0%|          | 0/100 [00:00<?, ?it/s, loss=0.395, lr=0.002]Steps:   0%|          | 0/100 [00:00<?, ?it/s, loss=0.546, lr=0.002]Steps:   0%|          | 0/100 [00:00<?, ?it/s, loss=0.571, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:45,  1.06s/it, loss=0.571, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:45,  1.06s/it, loss=0.576, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:45,  1.06s/it, loss=0.399, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:45,  1.06s/it, loss=0.446, lr=0.002]Steps:   1%|          | 1/100 [00:01<01:45,  1.06s/it, loss=0.459, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:43,  1.06s/it, loss=0.459, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:43,  1.06s/it, loss=0.572, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:43,  1.06s/it, loss=0.638, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:43,  1.06s/it, loss=0.573, lr=0.002]Steps:   2%|▏         | 2/100 [00:02<01:43,  1.06s/it, loss=0.58, lr=0.002] Steps:   3%|▎         | 3/100 [00:03<01:42,  1.05s/it, loss=0.58, lr=0.002]Steps:   3%|▎         | 3/100 [00:03<01:42,  1.05s/it, loss=0.595, lr=0.002]Steps:   3%|▎         | 3/100 [00:03<01:42,  1.05s/it, loss=0.569, lr=0.002]Steps:   3%|▎         | 3/100 [00:03<01:42,  1.05s/it, loss=0.58, lr=0.002] Steps:   3%|▎         | 3/100 [00:03<01:42,  1.05s/it, loss=0.58, lr=0.002]Steps:   4%|▍         | 4/100 [00:04<01:40,  1.05s/it, loss=0.58, lr=0.002]Steps:   4%|▍         | 4/100 [00:04<01:40,  1.05s/it, loss=0.588, lr=0.002]Steps:   4%|▍         | 4/100 [00:04<01:40,  1.05s/it, loss=0.387, lr=0.002]Steps:   4%|▍         | 4/100 [00:04<01:40,  1.05s/it, loss=0.406, lr=0.002]Steps:   4%|▍         | 4/100 [00:05<01:40,  1.05s/it, loss=0.533, lr=0.002]Steps:   5%|▌         | 5/100 [00:05<01:39,  1.05s/it, loss=0.533, lr=0.002]Steps:   5%|▌         | 5/100 [00:05<01:39,  1.05s/it, loss=0.576, lr=0.002]Steps:   5%|▌         | 5/100 [00:05<01:39,  1.05s/it, loss=0.407, lr=0.002]Steps:   5%|▌         | 5/100 [00:05<01:39,  1.05s/it, loss=0.584, lr=0.002]Steps:   5%|▌         | 5/100 [00:06<01:39,  1.05s/it, loss=0.583, lr=0.002]Steps:   6%|▌         | 6/100 [00:06<01:38,  1.05s/it, loss=0.583, lr=0.002]Steps:   6%|▌         | 6/100 [00:06<01:38,  1.05s/it, loss=0.54, lr=0.002] Steps:   6%|▌         | 6/100 [00:06<01:38,  1.05s/it, loss=0.507, lr=0.002]Steps:   6%|▌         | 6/100 [00:06<01:38,  1.05s/it, loss=0.452, lr=0.002]Steps:   6%|▌         | 6/100 [00:07<01:38,  1.05s/it, loss=0.412, lr=0.002]Steps:   7%|▋         | 7/100 [00:07<01:37,  1.05s/it, loss=0.412, lr=0.002]Steps:   7%|▋         | 7/100 [00:07<01:37,  1.05s/it, loss=0.584, lr=0.002]Steps:   7%|▋         | 7/100 [00:07<01:37,  1.05s/it, loss=0.421, lr=0.002]Steps:   7%|▋         | 7/100 [00:07<01:37,  1.05s/it, loss=0.573, lr=0.002]Steps:   7%|▋         | 7/100 [00:08<01:37,  1.05s/it, loss=0.565, lr=0.002]Steps:   8%|▊         | 8/100 [00:08<01:36,  1.05s/it, loss=0.565, lr=0.002]Steps:   8%|▊         | 8/100 [00:08<01:36,  1.05s/it, loss=0.498, lr=0.002]Steps:   8%|▊         | 8/100 [00:08<01:36,  1.05s/it, loss=0.57, lr=0.002] Steps:   8%|▊         | 8/100 [00:08<01:36,  1.05s/it, loss=0.551, lr=0.002]Steps:   8%|▊         | 8/100 [00:09<01:36,  1.05s/it, loss=0.579, lr=0.002]Steps:   9%|▉         | 9/100 [00:09<01:35,  1.05s/it, loss=0.579, lr=0.002]Steps:   9%|▉         | 9/100 [00:09<01:35,  1.05s/it, loss=0.581, lr=0.002]Steps:   9%|▉         | 9/100 [00:09<01:35,  1.05s/it, loss=0.528, lr=0.002]Steps:   9%|▉         | 9/100 [00:09<01:35,  1.05s/it, loss=0.386, lr=0.002]Steps:   9%|▉         | 9/100 [00:10<01:35,  1.05s/it, loss=0.39, lr=0.002] Steps:  10%|█         | 10/100 [00:10<01:34,  1.05s/it, loss=0.39, lr=0.002]Steps:  10%|█         | 10/100 [00:10<01:34,  1.05s/it, loss=0.487, lr=0.002]Steps:  10%|█         | 10/100 [00:10<01:34,  1.05s/it, loss=0.583, lr=0.002]Steps:  10%|█         | 10/100 [00:11<01:34,  1.05s/it, loss=0.579, lr=0.002]Steps:  10%|█         | 10/100 [00:11<01:34,  1.05s/it, loss=0.452, lr=0.002]Steps:  11%|█         | 11/100 [00:11<01:33,  1.05s/it, loss=0.452, lr=0.002]Steps:  11%|█         | 11/100 [00:11<01:33,  1.05s/it, loss=0.395, lr=0.002]Steps:  11%|█         | 11/100 [00:11<01:33,  1.05s/it, loss=0.486, lr=0.002]Steps:  11%|█         | 11/100 [00:12<01:33,  1.05s/it, loss=0.557, lr=0.002]Steps:  11%|█         | 11/100 [00:12<01:33,  1.05s/it, loss=0.535, lr=0.002]Steps:  12%|█▏        | 12/100 [00:12<01:32,  1.05s/it, loss=0.535, lr=0.002]Steps:  12%|█▏        | 12/100 [00:12<01:32,  1.05s/it, loss=0.564, lr=0.002]Steps:  12%|█▏        | 12/100 [00:12<01:32,  1.05s/it, loss=0.566, lr=0.002]Steps:  12%|█▏        | 12/100 [00:13<01:32,  1.05s/it, loss=0.574, lr=0.002]Steps:  12%|█▏        | 12/100 [00:13<01:32,  1.05s/it, loss=0.508, lr=0.002]Steps:  13%|█▎        | 13/100 [00:13<01:31,  1.05s/it, loss=0.508, lr=0.002]Steps:  13%|█▎        | 13/100 [00:13<01:31,  1.05s/it, loss=0.517, lr=0.002]Steps:  13%|█▎        | 13/100 [00:13<01:31,  1.05s/it, loss=0.523, lr=0.002]Steps:  13%|█▎        | 13/100 [00:14<01:31,  1.05s/it, loss=0.558, lr=0.002]Steps:  13%|█▎        | 13/100 [00:14<01:31,  1.05s/it, loss=0.377, lr=0.002]Steps:  14%|█▍        | 14/100 [00:14<01:30,  1.05s/it, loss=0.377, lr=0.002]Steps:  14%|█▍        | 14/100 [00:14<01:30,  1.05s/it, loss=0.499, lr=0.002]Steps:  14%|█▍        | 14/100 [00:14<01:30,  1.05s/it, loss=0.475, lr=0.002]Steps:  14%|█▍        | 14/100 [00:15<01:30,  1.05s/it, loss=0.56, lr=0.002] Steps:  14%|█▍        | 14/100 [00:15<01:30,  1.05s/it, loss=0.49, lr=0.002]Steps:  15%|█▌        | 15/100 [00:15<01:29,  1.05s/it, loss=0.49, lr=0.002]Steps:  15%|█▌        | 15/100 [00:15<01:29,  1.05s/it, loss=0.475, lr=0.002]Steps:  15%|█▌        | 15/100 [00:16<01:29,  1.05s/it, loss=0.531, lr=0.002]Steps:  15%|█▌        | 15/100 [00:16<01:29,  1.05s/it, loss=0.544, lr=0.002]Steps:  15%|█▌        | 15/100 [00:16<01:29,  1.05s/it, loss=0.565, lr=0.002]Steps:  16%|█▌        | 16/100 [00:16<01:28,  1.05s/it, loss=0.565, lr=0.002]Steps:  16%|█▌        | 16/100 [00:16<01:28,  1.05s/it, loss=0.382, lr=0.002]Steps:  16%|█▌        | 16/100 [00:17<01:28,  1.05s/it, loss=0.392, lr=0.002]Steps:  16%|█▌        | 16/100 [00:17<01:28,  1.05s/it, loss=0.604, lr=0.002]Steps:  16%|█▌        | 16/100 [00:17<01:28,  1.05s/it, loss=0.392, lr=0.002]Steps:  17%|█▋        | 17/100 [00:17<01:27,  1.05s/it, loss=0.392, lr=0.002]Steps:  17%|█▋        | 17/100 [00:17<01:27,  1.05s/it, loss=0.39, lr=0.002] Steps:  17%|█▋        | 17/100 [00:18<01:27,  1.05s/it, loss=0.576, lr=0.002]Steps:  17%|█▋        | 17/100 [00:18<01:27,  1.05s/it, loss=0.561, lr=0.002]Steps:  17%|█▋        | 17/100 [00:18<01:27,  1.05s/it, loss=0.381, lr=0.002]Steps:  18%|█▊        | 18/100 [00:18<01:26,  1.05s/it, loss=0.381, lr=0.002]Steps:  18%|█▊        | 18/100 [00:18<01:26,  1.05s/it, loss=0.481, lr=0.002]Steps:  18%|█▊        | 18/100 [00:19<01:26,  1.05s/it, loss=0.583, lr=0.002]Steps:  18%|█▊        | 18/100 [00:19<01:26,  1.05s/it, loss=0.382, lr=0.002]Steps:  18%|█▊        | 18/100 [00:19<01:26,  1.05s/it, loss=0.378, lr=0.002]Steps:  19%|█▉        | 19/100 [00:19<01:25,  1.05s/it, loss=0.378, lr=0.002]Steps:  19%|█▉        | 19/100 [00:19<01:25,  1.05s/it, loss=0.384, lr=0.002]Steps:  19%|█▉        | 19/100 [00:20<01:25,  1.05s/it, loss=0.569, lr=0.002]Steps:  19%|█▉        | 19/100 [00:20<01:25,  1.05s/it, loss=0.576, lr=0.002]Steps:  19%|█▉        | 19/100 [00:20<01:25,  1.05s/it, loss=0.601, lr=0.002]Steps:  20%|██        | 20/100 [00:21<01:24,  1.05s/it, loss=0.601, lr=0.002]Steps:  20%|██        | 20/100 [00:21<01:24,  1.05s/it, loss=0.421, lr=0.002]Steps:  20%|██        | 20/100 [00:21<01:24,  1.05s/it, loss=0.393, lr=0.002]Steps:  20%|██        | 20/100 [00:21<01:24,  1.05s/it, loss=0.59, lr=0.002] Steps:  20%|██        | 20/100 [00:21<01:24,  1.05s/it, loss=0.47, lr=0.002]Steps:  21%|██        | 21/100 [00:22<01:23,  1.05s/it, loss=0.47, lr=0.002]Steps:  21%|██        | 21/100 [00:22<01:23,  1.05s/it, loss=0.572, lr=0.002]Steps:  21%|██        | 21/100 [00:22<01:23,  1.05s/it, loss=0.436, lr=0.002]Steps:  21%|██        | 21/100 [00:22<01:23,  1.05s/it, loss=0.583, lr=0.002]Steps:  21%|██        | 21/100 [00:22<01:23,  1.05s/it, loss=0.473, lr=0.002]Steps:  22%|██▏       | 22/100 [00:23<01:21,  1.05s/it, loss=0.473, lr=0.002]Steps:  22%|██▏       | 22/100 [00:23<01:21,  1.05s/it, loss=0.392, lr=0.002]Steps:  22%|██▏       | 22/100 [00:23<01:21,  1.05s/it, loss=0.398, lr=0.002]Steps:  22%|██▏       | 22/100 [00:23<01:21,  1.05s/it, loss=0.419, lr=0.002]Steps:  22%|██▏       | 22/100 [00:23<01:21,  1.05s/it, loss=0.545, lr=0.002]Steps:  23%|██▎       | 23/100 [00:24<01:20,  1.05s/it, loss=0.545, lr=0.002]Steps:  23%|██▎       | 23/100 [00:24<01:20,  1.05s/it, loss=0.563, lr=0.002]Steps:  23%|██▎       | 23/100 [00:24<01:20,  1.05s/it, loss=0.408, lr=0.002]Steps:  23%|██▎       | 23/100 [00:24<01:20,  1.05s/it, loss=0.539, lr=0.002]Steps:  23%|██▎       | 23/100 [00:24<01:20,  1.05s/it, loss=0.569, lr=0.002]Steps:  24%|██▍       | 24/100 [00:25<01:19,  1.05s/it, loss=0.569, lr=0.002]Steps:  24%|██▍       | 24/100 [00:25<01:19,  1.05s/it, loss=0.388, lr=0.002]Steps:  24%|██▍       | 24/100 [00:25<01:19,  1.05s/it, loss=0.569, lr=0.002]Steps:  24%|██▍       | 24/100 [00:25<01:19,  1.05s/it, loss=0.466, lr=0.002]Steps:  24%|██▍       | 24/100 [00:26<01:19,  1.05s/it, loss=0.592, lr=0.002]Steps:  25%|██▌       | 25/100 [00:26<01:17,  1.04s/it, loss=0.592, lr=0.002]Steps:  25%|██▌       | 25/100 [00:26<01:17,  1.04s/it, loss=0.588, lr=0.002]Steps:  25%|██▌       | 25/100 [00:26<01:17,  1.04s/it, loss=0.394, lr=0.002]Steps:  25%|██▌       | 25/100 [00:26<01:17,  1.04s/it, loss=0.533, lr=0.002]Steps:  25%|██▌       | 25/100 [00:27<01:17,  1.04s/it, loss=0.516, lr=0.002]Steps:  26%|██▌       | 26/100 [00:27<01:17,  1.05s/it, loss=0.516, lr=0.002]Steps:  26%|██▌       | 26/100 [00:27<01:17,  1.05s/it, loss=0.57, lr=0.002] Steps:  26%|██▌       | 26/100 [00:27<01:17,  1.05s/it, loss=0.493, lr=0.002]Steps:  26%|██▌       | 26/100 [00:27<01:17,  1.05s/it, loss=0.511, lr=0.002]Steps:  26%|██▌       | 26/100 [00:28<01:17,  1.05s/it, loss=0.541, lr=0.002]Steps:  27%|██▋       | 27/100 [00:28<01:16,  1.05s/it, loss=0.541, lr=0.002]Steps:  27%|██▋       | 27/100 [00:28<01:16,  1.05s/it, loss=0.54, lr=0.002] Steps:  27%|██▋       | 27/100 [00:28<01:16,  1.05s/it, loss=0.513, lr=0.002]Steps:  27%|██▋       | 27/100 [00:28<01:16,  1.05s/it, loss=0.398, lr=0.002]Steps:  27%|██▋       | 27/100 [00:29<01:16,  1.05s/it, loss=0.414, lr=0.002]Steps:  28%|██▊       | 28/100 [00:29<01:15,  1.05s/it, loss=0.414, lr=0.002]Steps:  28%|██▊       | 28/100 [00:29<01:15,  1.05s/it, loss=0.587, lr=0.002]Steps:  28%|██▊       | 28/100 [00:29<01:15,  1.05s/it, loss=0.565, lr=0.002]Steps:  28%|██▊       | 28/100 [00:29<01:15,  1.05s/it, loss=0.609, lr=0.002]Steps:  28%|██▊       | 28/100 [00:30<01:15,  1.05s/it, loss=0.442, lr=0.002]Steps:  29%|██▉       | 29/100 [00:30<01:14,  1.05s/it, loss=0.442, lr=0.002]Steps:  29%|██▉       | 29/100 [00:30<01:14,  1.05s/it, loss=0.562, lr=0.002]Steps:  29%|██▉       | 29/100 [00:30<01:14,  1.05s/it, loss=0.559, lr=0.002]Steps:  29%|██▉       | 29/100 [00:30<01:14,  1.05s/it, loss=0.618, lr=0.002]Steps:  29%|██▉       | 29/100 [00:31<01:14,  1.05s/it, loss=0.541, lr=0.002]Steps:  30%|███       | 30/100 [00:31<01:13,  1.05s/it, loss=0.541, lr=0.002]Steps:  30%|███       | 30/100 [00:31<01:13,  1.05s/it, loss=0.546, lr=0.002]Steps:  30%|███       | 30/100 [00:31<01:13,  1.05s/it, loss=0.511, lr=0.002]Steps:  30%|███       | 30/100 [00:32<01:13,  1.05s/it, loss=0.589, lr=0.002]Steps:  30%|███       | 30/100 [00:32<01:13,  1.05s/it, loss=0.522, lr=0.002]Steps:  31%|███       | 31/100 [00:32<01:12,  1.05s/it, loss=0.522, lr=0.002]Steps:  31%|███       | 31/100 [00:32<01:12,  1.05s/it, loss=0.574, lr=0.002]Steps:  31%|███       | 31/100 [00:32<01:12,  1.05s/it, loss=0.553, lr=0.002]Steps:  31%|███       | 31/100 [00:33<01:12,  1.05s/it, loss=0.584, lr=0.002]Steps:  31%|███       | 31/100 [00:33<01:12,  1.05s/it, loss=0.561, lr=0.002]Steps:  32%|███▏      | 32/100 [00:33<01:11,  1.05s/it, loss=0.561, lr=0.002]Steps:  32%|███▏      | 32/100 [00:33<01:11,  1.05s/it, loss=0.386, lr=0.002]Steps:  32%|███▏      | 32/100 [00:33<01:11,  1.05s/it, loss=0.389, lr=0.002]Steps:  32%|███▏      | 32/100 [00:34<01:11,  1.05s/it, loss=0.378, lr=0.002]Steps:  32%|███▏      | 32/100 [00:34<01:11,  1.05s/it, loss=0.561, lr=0.002]Steps:  33%|███▎      | 33/100 [00:34<01:10,  1.05s/it, loss=0.561, lr=0.002]Steps:  33%|███▎      | 33/100 [00:34<01:10,  1.05s/it, loss=0.582, lr=0.002]Steps:  33%|███▎      | 33/100 [00:34<01:10,  1.05s/it, loss=0.571, lr=0.002]Steps:  33%|███▎      | 33/100 [00:35<01:10,  1.05s/it, loss=0.495, lr=0.002]Steps:  33%|███▎      | 33/100 [00:35<01:10,  1.05s/it, loss=0.472, lr=0.002]Steps:  34%|███▍      | 34/100 [00:35<01:09,  1.05s/it, loss=0.472, lr=0.002]Steps:  34%|███▍      | 34/100 [00:35<01:09,  1.05s/it, loss=0.572, lr=0.002]Steps:  34%|███▍      | 34/100 [00:35<01:09,  1.05s/it, loss=0.415, lr=0.002]Steps:  34%|███▍      | 34/100 [00:36<01:09,  1.05s/it, loss=0.422, lr=0.002]Steps:  34%|███▍      | 34/100 [00:36<01:09,  1.05s/it, loss=0.395, lr=0.002]Steps:  35%|███▌      | 35/100 [00:36<01:08,  1.05s/it, loss=0.395, lr=0.002]Steps:  35%|███▌      | 35/100 [00:36<01:08,  1.05s/it, loss=0.564, lr=0.002]Steps:  35%|███▌      | 35/100 [00:37<01:08,  1.05s/it, loss=0.513, lr=0.002]Steps:  35%|███▌      | 35/100 [00:37<01:08,  1.05s/it, loss=0.561, lr=0.002]Steps:  35%|███▌      | 35/100 [00:37<01:08,  1.05s/it, loss=0.521, lr=0.002]Steps:  36%|███▌      | 36/100 [00:37<01:07,  1.05s/it, loss=0.521, lr=0.002]Steps:  36%|███▌      | 36/100 [00:37<01:07,  1.05s/it, loss=0.606, lr=0.002]Steps:  36%|███▌      | 36/100 [00:38<01:07,  1.05s/it, loss=0.642, lr=0.002]Steps:  36%|███▌      | 36/100 [00:38<01:07,  1.05s/it, loss=0.392, lr=0.002]Steps:  36%|███▌      | 36/100 [00:38<01:07,  1.05s/it, loss=0.572, lr=0.002]Steps:  37%|███▋      | 37/100 [00:38<01:06,  1.05s/it, loss=0.572, lr=0.002]Steps:  37%|███▋      | 37/100 [00:38<01:06,  1.05s/it, loss=0.563, lr=0.002]Steps:  37%|███▋      | 37/100 [00:39<01:06,  1.05s/it, loss=0.452, lr=0.002]Steps:  37%|███▋      | 37/100 [00:39<01:06,  1.05s/it, loss=0.564, lr=0.002]Steps:  37%|███▋      | 37/100 [00:39<01:06,  1.05s/it, loss=0.576, lr=0.002]Steps:  38%|███▊      | 38/100 [00:39<01:05,  1.05s/it, loss=0.576, lr=0.002]Steps:  38%|███▊      | 38/100 [00:39<01:05,  1.05s/it, loss=0.56, lr=0.002] Steps:  38%|███▊      | 38/100 [00:40<01:05,  1.05s/it, loss=0.526, lr=0.002]Steps:  38%|███▊      | 38/100 [00:40<01:05,  1.05s/it, loss=0.568, lr=0.002]Steps:  38%|███▊      | 38/100 [00:40<01:05,  1.05s/it, loss=0.529, lr=0.002]Steps:  39%|███▉      | 39/100 [00:40<01:04,  1.05s/it, loss=0.529, lr=0.002]Steps:  39%|███▉      | 39/100 [00:40<01:04,  1.05s/it, loss=0.559, lr=0.002]Steps:  39%|███▉      | 39/100 [00:41<01:04,  1.05s/it, loss=0.45, lr=0.002] Steps:  39%|███▉      | 39/100 [00:41<01:04,  1.05s/it, loss=0.543, lr=0.002]Steps:  39%|███▉      | 39/100 [00:41<01:04,  1.05s/it, loss=0.5, lr=0.002]  Steps:  40%|████      | 40/100 [00:42<01:02,  1.05s/it, loss=0.5, lr=0.002]Steps:  40%|████      | 40/100 [00:42<01:02,  1.05s/it, loss=0.579, lr=0.002]Steps:  40%|████      | 40/100 [00:42<01:02,  1.05s/it, loss=0.537, lr=0.002]Steps:  40%|████      | 40/100 [00:42<01:02,  1.05s/it, loss=0.507, lr=0.002]Steps:  40%|████      | 40/100 [00:42<01:02,  1.05s/it, loss=0.451, lr=0.002]Steps:  41%|████      | 41/100 [00:43<01:01,  1.05s/it, loss=0.451, lr=0.002]Steps:  41%|████      | 41/100 [00:43<01:01,  1.05s/it, loss=0.52, lr=0.002] Steps:  41%|████      | 41/100 [00:43<01:01,  1.05s/it, loss=0.422, lr=0.002]Steps:  41%|████      | 41/100 [00:43<01:01,  1.05s/it, loss=0.505, lr=0.002]Steps:  41%|████      | 41/100 [00:43<01:01,  1.05s/it, loss=0.385, lr=0.002]Steps:  42%|████▏     | 42/100 [00:44<01:00,  1.05s/it, loss=0.385, lr=0.002]Steps:  42%|████▏     | 42/100 [00:44<01:00,  1.05s/it, loss=0.455, lr=0.002]Steps:  42%|████▏     | 42/100 [00:44<01:00,  1.05s/it, loss=0.577, lr=0.002]Steps:  42%|████▏     | 42/100 [00:44<01:00,  1.05s/it, loss=0.494, lr=0.002]Steps:  42%|████▏     | 42/100 [00:44<01:00,  1.05s/it, loss=0.577, lr=0.002]Steps:  43%|████▎     | 43/100 [00:45<00:59,  1.05s/it, loss=0.577, lr=0.002]Steps:  43%|████▎     | 43/100 [00:45<00:59,  1.05s/it, loss=0.379, lr=0.002]Steps:  43%|████▎     | 43/100 [00:45<00:59,  1.05s/it, loss=0.557, lr=0.002]Steps:  43%|████▎     | 43/100 [00:45<00:59,  1.05s/it, loss=0.445, lr=0.002]Steps:  43%|████▎     | 43/100 [00:45<00:59,  1.05s/it, loss=0.43, lr=0.002] Steps:  44%|████▍     | 44/100 [00:46<00:58,  1.05s/it, loss=0.43, lr=0.002]Steps:  44%|████▍     | 44/100 [00:46<00:58,  1.05s/it, loss=0.567, lr=0.002]Steps:  44%|████▍     | 44/100 [00:46<00:58,  1.05s/it, loss=0.585, lr=0.002]Steps:  44%|████▍     | 44/100 [00:46<00:58,  1.05s/it, loss=0.468, lr=0.002]Steps:  44%|████▍     | 44/100 [00:47<00:58,  1.05s/it, loss=0.379, lr=0.002]Steps:  45%|████▌     | 45/100 [00:47<00:57,  1.05s/it, loss=0.379, lr=0.002]Steps:  45%|████▌     | 45/100 [00:47<00:57,  1.05s/it, loss=0.391, lr=0.002]Steps:  45%|████▌     | 45/100 [00:47<00:57,  1.05s/it, loss=0.401, lr=0.002]Steps:  45%|████▌     | 45/100 [00:47<00:57,  1.05s/it, loss=0.413, lr=0.002]Steps:  45%|████▌     | 45/100 [00:48<00:57,  1.05s/it, loss=0.479, lr=0.002]Steps:  46%|████▌     | 46/100 [00:48<00:56,  1.05s/it, loss=0.479, lr=0.002]Steps:  46%|████▌     | 46/100 [00:48<00:56,  1.05s/it, loss=0.564, lr=0.002]Steps:  46%|████▌     | 46/100 [00:48<00:56,  1.05s/it, loss=0.581, lr=0.002]Steps:  46%|████▌     | 46/100 [00:48<00:56,  1.05s/it, loss=0.568, lr=0.002]Steps:  46%|████▌     | 46/100 [00:49<00:56,  1.05s/it, loss=0.461, lr=0.002]Steps:  47%|████▋     | 47/100 [00:49<00:55,  1.05s/it, loss=0.461, lr=0.002]Steps:  47%|████▋     | 47/100 [00:49<00:55,  1.05s/it, loss=0.575, lr=0.002]Steps:  47%|████▋     | 47/100 [00:49<00:55,  1.05s/it, loss=0.481, lr=0.002]Steps:  47%|████▋     | 47/100 [00:49<00:55,  1.05s/it, loss=0.572, lr=0.002]Steps:  47%|████▋     | 47/100 [00:50<00:55,  1.05s/it, loss=0.521, lr=0.002]Steps:  48%|████▊     | 48/100 [00:50<00:54,  1.05s/it, loss=0.521, lr=0.002]Steps:  48%|████▊     | 48/100 [00:50<00:54,  1.05s/it, loss=0.457, lr=0.002]Steps:  48%|████▊     | 48/100 [00:50<00:54,  1.05s/it, loss=0.404, lr=0.002]Steps:  48%|████▊     | 48/100 [00:50<00:54,  1.05s/it, loss=0.522, lr=0.002]Steps:  48%|████▊     | 48/100 [00:51<00:54,  1.05s/it, loss=0.568, lr=0.002]Steps:  49%|████▉     | 49/100 [00:51<00:53,  1.05s/it, loss=0.568, lr=0.002]Steps:  49%|████▉     | 49/100 [00:51<00:53,  1.05s/it, loss=0.493, lr=0.002]Steps:  49%|████▉     | 49/100 [00:51<00:53,  1.05s/it, loss=0.519, lr=0.002]Steps:  49%|████▉     | 49/100 [00:51<00:53,  1.05s/it, loss=0.41, lr=0.002] Steps:  49%|████▉     | 49/100 [00:52<00:53,  1.05s/it, loss=0.511, lr=0.002]Steps:  50%|█████     | 50/100 [00:52<00:52,  1.04s/it, loss=0.511, lr=0.002]Steps:  50%|█████     | 50/100 [00:52<00:52,  1.04s/it, loss=0.569, lr=0.002]Steps:  50%|█████     | 50/100 [00:52<00:52,  1.04s/it, loss=0.507, lr=0.002]Steps:  50%|█████     | 50/100 [00:53<00:52,  1.04s/it, loss=0.576, lr=0.002]Steps:  50%|█████     | 50/100 [00:53<00:52,  1.04s/it, loss=0.487, lr=0.002]Steps:  51%|█████     | 51/100 [00:53<00:51,  1.05s/it, loss=0.487, lr=0.002]Steps:  51%|█████     | 51/100 [00:53<00:51,  1.05s/it, loss=0.441, lr=0.002]Steps:  51%|█████     | 51/100 [00:53<00:51,  1.05s/it, loss=0.554, lr=0.002]Steps:  51%|█████     | 51/100 [00:54<00:51,  1.05s/it, loss=0.42, lr=0.002] Steps:  51%|█████     | 51/100 [00:54<00:51,  1.05s/it, loss=0.567, lr=0.002]Steps:  52%|█████▏    | 52/100 [00:54<00:50,  1.05s/it, loss=0.567, lr=0.002]Steps:  52%|█████▏    | 52/100 [00:54<00:50,  1.05s/it, loss=0.48, lr=0.002] Steps:  52%|█████▏    | 52/100 [00:54<00:50,  1.05s/it, loss=0.531, lr=0.002]Steps:  52%|█████▏    | 52/100 [00:55<00:50,  1.05s/it, loss=0.383, lr=0.002]Steps:  52%|█████▏    | 52/100 [00:55<00:50,  1.05s/it, loss=0.581, lr=0.002]Steps:  53%|█████▎    | 53/100 [00:55<00:49,  1.05s/it, loss=0.581, lr=0.002]Steps:  53%|█████▎    | 53/100 [00:55<00:49,  1.05s/it, loss=0.558, lr=0.002]Steps:  53%|█████▎    | 53/100 [00:55<00:49,  1.05s/it, loss=0.553, lr=0.002]Steps:  53%|█████▎    | 53/100 [00:56<00:49,  1.05s/it, loss=0.471, lr=0.002]Steps:  53%|█████▎    | 53/100 [00:56<00:49,  1.05s/it, loss=0.575, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:56<00:48,  1.05s/it, loss=0.575, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:56<00:48,  1.05s/it, loss=0.402, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:56<00:48,  1.05s/it, loss=0.474, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:57<00:48,  1.05s/it, loss=0.471, lr=0.002]Steps:  54%|█████▍    | 54/100 [00:57<00:48,  1.05s/it, loss=0.379, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:57<00:47,  1.05s/it, loss=0.379, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:57<00:47,  1.05s/it, loss=0.511, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:58<00:47,  1.05s/it, loss=0.525, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:58<00:47,  1.05s/it, loss=0.514, lr=0.002]Steps:  55%|█████▌    | 55/100 [00:58<00:47,  1.05s/it, loss=0.585, lr=0.002]Steps:  56%|█████▌    | 56/100 [00:58<00:46,  1.05s/it, loss=0.585, lr=0.002]Steps:  56%|█████▌    | 56/100 [00:58<00:46,  1.05s/it, loss=0.45, lr=0.002] Steps:  56%|█████▌    | 56/100 [00:59<00:46,  1.05s/it, loss=0.459, lr=0.002]Steps:  56%|█████▌    | 56/100 [00:59<00:46,  1.05s/it, loss=0.392, lr=0.002]Steps:  56%|█████▌    | 56/100 [00:59<00:46,  1.05s/it, loss=0.389, lr=0.002]Steps:  57%|█████▋    | 57/100 [00:59<00:45,  1.05s/it, loss=0.389, lr=0.002]Steps:  57%|█████▋    | 57/100 [00:59<00:45,  1.05s/it, loss=0.564, lr=0.002]Steps:  57%|█████▋    | 57/100 [01:00<00:45,  1.05s/it, loss=0.563, lr=0.002]Steps:  57%|█████▋    | 57/100 [01:00<00:45,  1.05s/it, loss=0.439, lr=0.002]Steps:  57%|█████▋    | 57/100 [01:00<00:45,  1.05s/it, loss=0.572, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:00<00:44,  1.05s/it, loss=0.572, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:00<00:44,  1.05s/it, loss=0.401, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:01<00:44,  1.05s/it, loss=0.488, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:01<00:44,  1.05s/it, loss=0.381, lr=0.002]Steps:  58%|█████▊    | 58/100 [01:01<00:44,  1.05s/it, loss=0.401, lr=0.002]Steps:  59%|█████▉    | 59/100 [01:01<00:43,  1.05s/it, loss=0.401, lr=0.002]Steps:  59%|█████▉    | 59/100 [01:01<00:43,  1.05s/it, loss=0.56, lr=0.002] Steps:  59%|█████▉    | 59/100 [01:02<00:43,  1.05s/it, loss=0.439, lr=0.002]Steps:  59%|█████▉    | 59/100 [01:02<00:43,  1.05s/it, loss=0.566, lr=0.002]Steps:  59%|█████▉    | 59/100 [01:02<00:43,  1.05s/it, loss=0.544, lr=0.002]Steps:  60%|██████    | 60/100 [01:03<00:42,  1.05s/it, loss=0.544, lr=0.002]Steps:  60%|██████    | 60/100 [01:03<00:42,  1.05s/it, loss=0.429, lr=0.002]Steps:  60%|██████    | 60/100 [01:03<00:42,  1.05s/it, loss=0.551, lr=0.002]Steps:  60%|██████    | 60/100 [01:03<00:42,  1.05s/it, loss=0.574, lr=0.002]Steps:  60%|██████    | 60/100 [01:03<00:42,  1.05s/it, loss=0.419, lr=0.002]Steps:  61%|██████    | 61/100 [01:04<00:41,  1.05s/it, loss=0.419, lr=0.002]Steps:  61%|██████    | 61/100 [01:04<00:41,  1.05s/it, loss=0.569, lr=0.002]Steps:  61%|██████    | 61/100 [01:04<00:41,  1.05s/it, loss=0.404, lr=0.002]Steps:  61%|██████    | 61/100 [01:04<00:41,  1.05s/it, loss=0.445, lr=0.002]Steps:  61%|██████    | 61/100 [01:04<00:41,  1.05s/it, loss=0.477, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:05<00:39,  1.05s/it, loss=0.477, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:05<00:39,  1.05s/it, loss=0.574, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:05<00:39,  1.05s/it, loss=0.579, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:05<00:39,  1.05s/it, loss=0.473, lr=0.002]Steps:  62%|██████▏   | 62/100 [01:05<00:39,  1.05s/it, loss=0.417, lr=0.002]Steps:  63%|██████▎   | 63/100 [01:06<00:38,  1.05s/it, loss=0.417, lr=0.002]Steps:  63%|██████▎   | 63/100 [01:06<00:38,  1.05s/it, loss=0.5, lr=0.002]  Steps:  63%|██████▎   | 63/100 [01:06<00:38,  1.05s/it, loss=0.553, lr=0.002]Steps:  63%|██████▎   | 63/100 [01:06<00:38,  1.05s/it, loss=0.389, lr=0.002]Steps:  63%|██████▎   | 63/100 [01:06<00:38,  1.05s/it, loss=0.574, lr=0.002]Steps:  64%|██████▍   | 64/100 [01:07<00:37,  1.05s/it, loss=0.574, lr=0.002]Steps:  64%|██████▍   | 64/100 [01:07<00:37,  1.05s/it, loss=0.437, lr=0.002]Steps:  64%|██████▍   | 64/100 [01:07<00:37,  1.05s/it, loss=0.523, lr=0.002]Steps:  64%|██████▍   | 64/100 [01:07<00:37,  1.05s/it, loss=0.582, lr=0.002]Steps:  64%|██████▍   | 64/100 [01:08<00:37,  1.05s/it, loss=0.539, lr=0.002]Steps:  65%|██████▌   | 65/100 [01:08<00:36,  1.05s/it, loss=0.539, lr=0.002]Steps:  65%|██████▌   | 65/100 [01:08<00:36,  1.05s/it, loss=0.58, lr=0.002] Steps:  65%|██████▌   | 65/100 [01:08<00:36,  1.05s/it, loss=0.576, lr=0.002]Steps:  65%|██████▌   | 65/100 [01:08<00:36,  1.05s/it, loss=0.575, lr=0.002]Steps:  65%|██████▌   | 65/100 [01:09<00:36,  1.05s/it, loss=0.47, lr=0.002] Steps:  66%|██████▌   | 66/100 [01:09<00:35,  1.05s/it, loss=0.47, lr=0.002]Steps:  66%|██████▌   | 66/100 [01:09<00:35,  1.05s/it, loss=0.535, lr=0.002]Steps:  66%|██████▌   | 66/100 [01:09<00:35,  1.05s/it, loss=0.41, lr=0.002] Steps:  66%|██████▌   | 66/100 [01:09<00:35,  1.05s/it, loss=0.612, lr=0.002]Steps:  66%|██████▌   | 66/100 [01:10<00:35,  1.05s/it, loss=0.561, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:10<00:34,  1.05s/it, loss=0.561, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:10<00:34,  1.05s/it, loss=0.374, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:10<00:34,  1.05s/it, loss=0.514, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:10<00:34,  1.05s/it, loss=0.377, lr=0.002]Steps:  67%|██████▋   | 67/100 [01:11<00:34,  1.05s/it, loss=0.399, lr=0.002]Steps:  68%|██████▊   | 68/100 [01:11<00:33,  1.05s/it, loss=0.399, lr=0.002]Steps:  68%|██████▊   | 68/100 [01:11<00:33,  1.05s/it, loss=0.581, lr=0.002]Steps:  68%|██████▊   | 68/100 [01:11<00:33,  1.05s/it, loss=0.505, lr=0.002]Steps:  68%|██████▊   | 68/100 [01:11<00:33,  1.05s/it, loss=0.56, lr=0.002] Steps:  68%|██████▊   | 68/100 [01:12<00:33,  1.05s/it, loss=0.488, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:12<00:32,  1.05s/it, loss=0.488, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:12<00:32,  1.05s/it, loss=0.568, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:12<00:32,  1.05s/it, loss=0.536, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:12<00:32,  1.05s/it, loss=0.501, lr=0.002]Steps:  69%|██████▉   | 69/100 [01:13<00:32,  1.05s/it, loss=0.593, lr=0.002]Steps:  70%|███████   | 70/100 [01:13<00:31,  1.05s/it, loss=0.593, lr=0.002]Steps:  70%|███████   | 70/100 [01:13<00:31,  1.05s/it, loss=0.526, lr=0.002]Steps:  70%|███████   | 70/100 [01:13<00:31,  1.05s/it, loss=0.561, lr=0.002]Steps:  70%|███████   | 70/100 [01:14<00:31,  1.05s/it, loss=0.583, lr=0.002]Steps:  70%|███████   | 70/100 [01:14<00:31,  1.05s/it, loss=0.382, lr=0.002]Steps:  71%|███████   | 71/100 [01:14<00:30,  1.05s/it, loss=0.382, lr=0.002]Steps:  71%|███████   | 71/100 [01:14<00:30,  1.05s/it, loss=0.45, lr=0.002] Steps:  71%|███████   | 71/100 [01:14<00:30,  1.05s/it, loss=0.419, lr=0.002]Steps:  71%|███████   | 71/100 [01:15<00:30,  1.05s/it, loss=0.401, lr=0.002]Steps:  71%|███████   | 71/100 [01:15<00:30,  1.05s/it, loss=0.596, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:15<00:29,  1.05s/it, loss=0.596, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:15<00:29,  1.05s/it, loss=0.407, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:15<00:29,  1.05s/it, loss=0.582, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:16<00:29,  1.05s/it, loss=0.568, lr=0.002]Steps:  72%|███████▏  | 72/100 [01:16<00:29,  1.05s/it, loss=0.555, lr=0.002]Steps:  73%|███████▎  | 73/100 [01:16<00:28,  1.05s/it, loss=0.555, lr=0.002]Steps:  73%|███████▎  | 73/100 [01:16<00:28,  1.05s/it, loss=0.39, lr=0.002] Steps:  73%|███████▎  | 73/100 [01:16<00:28,  1.05s/it, loss=0.564, lr=0.002]Steps:  73%|███████▎  | 73/100 [01:17<00:28,  1.05s/it, loss=0.46, lr=0.002] Steps:  73%|███████▎  | 73/100 [01:17<00:28,  1.05s/it, loss=0.532, lr=0.002]Steps:  74%|███████▍  | 74/100 [01:17<00:27,  1.05s/it, loss=0.532, lr=0.002]Steps:  74%|███████▍  | 74/100 [01:17<00:27,  1.05s/it, loss=0.52, lr=0.002] Steps:  74%|███████▍  | 74/100 [01:17<00:27,  1.05s/it, loss=0.564, lr=0.002]Steps:  74%|███████▍  | 74/100 [01:18<00:27,  1.05s/it, loss=0.49, lr=0.002] Steps:  74%|███████▍  | 74/100 [01:18<00:27,  1.05s/it, loss=0.548, lr=0.002]Steps:  75%|███████▌  | 75/100 [01:18<00:26,  1.04s/it, loss=0.548, lr=0.002]Steps:  75%|███████▌  | 75/100 [01:18<00:26,  1.04s/it, loss=0.413, lr=0.002]Steps:  75%|███████▌  | 75/100 [01:19<00:26,  1.04s/it, loss=0.566, lr=0.002]Steps:  75%|███████▌  | 75/100 [01:19<00:26,  1.04s/it, loss=0.427, lr=0.002]Steps:  75%|███████▌  | 75/100 [01:19<00:26,  1.04s/it, loss=0.459, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:19<00:25,  1.05s/it, loss=0.459, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:19<00:25,  1.05s/it, loss=0.415, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:20<00:25,  1.05s/it, loss=0.576, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:20<00:25,  1.05s/it, loss=0.516, lr=0.002]Steps:  76%|███████▌  | 76/100 [01:20<00:25,  1.05s/it, loss=0.561, lr=0.002]Steps:  77%|███████▋  | 77/100 [01:20<00:24,  1.05s/it, loss=0.561, lr=0.002]Steps:  77%|███████▋  | 77/100 [01:20<00:24,  1.05s/it, loss=0.569, lr=0.002]Steps:  77%|███████▋  | 77/100 [01:21<00:24,  1.05s/it, loss=0.386, lr=0.002]Steps:  77%|███████▋  | 77/100 [01:21<00:24,  1.05s/it, loss=0.403, lr=0.002]Steps:  77%|███████▋  | 77/100 [01:21<00:24,  1.05s/it, loss=0.557, lr=0.002]Steps:  78%|███████▊  | 78/100 [01:21<00:23,  1.05s/it, loss=0.557, lr=0.002]Steps:  78%|███████▊  | 78/100 [01:21<00:23,  1.05s/it, loss=0.379, lr=0.002]Steps:  78%|███████▊  | 78/100 [01:22<00:23,  1.05s/it, loss=0.57, lr=0.002] Steps:  78%|███████▊  | 78/100 [01:22<00:23,  1.05s/it, loss=0.382, lr=0.002]Steps:  78%|███████▊  | 78/100 [01:22<00:23,  1.05s/it, loss=0.499, lr=0.002]Steps:  79%|███████▉  | 79/100 [01:22<00:22,  1.05s/it, loss=0.499, lr=0.002]Steps:  79%|███████▉  | 79/100 [01:22<00:22,  1.05s/it, loss=0.463, lr=0.002]Steps:  79%|███████▉  | 79/100 [01:23<00:22,  1.05s/it, loss=0.54, lr=0.002] Steps:  79%|███████▉  | 79/100 [01:23<00:22,  1.05s/it, loss=0.571, lr=0.002]Steps:  79%|███████▉  | 79/100 [01:23<00:22,  1.05s/it, loss=0.525, lr=0.002]Steps:  80%|████████  | 80/100 [01:24<00:21,  1.05s/it, loss=0.525, lr=0.002]Steps:  80%|████████  | 80/100 [01:24<00:21,  1.05s/it, loss=0.39, lr=0.002] Steps:  80%|████████  | 80/100 [01:24<00:21,  1.05s/it, loss=0.553, lr=0.002]Steps:  80%|████████  | 80/100 [01:24<00:21,  1.05s/it, loss=0.559, lr=0.002]Steps:  80%|████████  | 80/100 [01:24<00:21,  1.05s/it, loss=0.501, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:19,  1.05s/it, loss=0.501, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:19,  1.05s/it, loss=0.598, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:19,  1.05s/it, loss=0.512, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:19,  1.05s/it, loss=0.542, lr=0.002]Steps:  81%|████████  | 81/100 [01:25<00:19,  1.05s/it, loss=0.444, lr=0.002]Steps:  82%|████████▏ | 82/100 [01:26<00:18,  1.05s/it, loss=0.444, lr=0.002]Steps:  82%|████████▏ | 82/100 [01:26<00:18,  1.05s/it, loss=0.559, lr=0.002]Steps:  82%|████████▏ | 82/100 [01:26<00:18,  1.05s/it, loss=0.53, lr=0.002] Steps:  82%|████████▏ | 82/100 [01:26<00:18,  1.05s/it, loss=0.519, lr=0.002]Steps:  82%|████████▏ | 82/100 [01:26<00:18,  1.05s/it, loss=0.563, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:27<00:17,  1.05s/it, loss=0.563, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:27<00:17,  1.05s/it, loss=0.555, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:27<00:17,  1.05s/it, loss=0.412, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:27<00:17,  1.05s/it, loss=0.571, lr=0.002]Steps:  83%|████████▎ | 83/100 [01:27<00:17,  1.05s/it, loss=0.577, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:28<00:16,  1.05s/it, loss=0.577, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:28<00:16,  1.05s/it, loss=0.525, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:28<00:16,  1.05s/it, loss=0.421, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:28<00:16,  1.05s/it, loss=0.458, lr=0.002]Steps:  84%|████████▍ | 84/100 [01:29<00:16,  1.05s/it, loss=0.418, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:29<00:15,  1.05s/it, loss=0.418, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:29<00:15,  1.05s/it, loss=0.544, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:29<00:15,  1.05s/it, loss=0.415, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:29<00:15,  1.05s/it, loss=0.529, lr=0.002]Steps:  85%|████████▌ | 85/100 [01:30<00:15,  1.05s/it, loss=0.467, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:30<00:14,  1.05s/it, loss=0.467, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:30<00:14,  1.05s/it, loss=0.446, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:30<00:14,  1.05s/it, loss=0.567, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:30<00:14,  1.05s/it, loss=0.565, lr=0.002]Steps:  86%|████████▌ | 86/100 [01:31<00:14,  1.05s/it, loss=0.534, lr=0.002]Steps:  87%|████████▋ | 87/100 [01:31<00:13,  1.05s/it, loss=0.534, lr=0.002]Steps:  87%|████████▋ | 87/100 [01:31<00:13,  1.05s/it, loss=0.389, lr=0.002]Steps:  87%|████████▋ | 87/100 [01:31<00:13,  1.05s/it, loss=0.55, lr=0.002] Steps:  87%|████████▋ | 87/100 [01:31<00:13,  1.05s/it, loss=0.472, lr=0.002]Steps:  87%|████████▋ | 87/100 [01:32<00:13,  1.05s/it, loss=0.575, lr=0.002]Steps:  88%|████████▊ | 88/100 [01:32<00:12,  1.05s/it, loss=0.575, lr=0.002]Steps:  88%|████████▊ | 88/100 [01:32<00:12,  1.05s/it, loss=0.576, lr=0.002]Steps:  88%|████████▊ | 88/100 [01:32<00:12,  1.05s/it, loss=0.437, lr=0.002]Steps:  88%|████████▊ | 88/100 [01:32<00:12,  1.05s/it, loss=0.4, lr=0.002]  Steps:  88%|████████▊ | 88/100 [01:33<00:12,  1.05s/it, loss=0.564, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:33<00:11,  1.05s/it, loss=0.564, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:33<00:11,  1.05s/it, loss=0.387, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:33<00:11,  1.05s/it, loss=0.389, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:34<00:11,  1.05s/it, loss=0.554, lr=0.002]Steps:  89%|████████▉ | 89/100 [01:34<00:11,  1.05s/it, loss=0.534, lr=0.002]Steps:  90%|█████████ | 90/100 [01:34<00:10,  1.05s/it, loss=0.534, lr=0.002]Steps:  90%|█████████ | 90/100 [01:34<00:10,  1.05s/it, loss=0.428, lr=0.002]Steps:  90%|█████████ | 90/100 [01:34<00:10,  1.05s/it, loss=0.573, lr=0.002]Steps:  90%|█████████ | 90/100 [01:35<00:10,  1.05s/it, loss=0.692, lr=0.002]Steps:  90%|█████████ | 90/100 [01:35<00:10,  1.05s/it, loss=0.549, lr=0.002]Steps:  91%|█████████ | 91/100 [01:35<00:09,  1.05s/it, loss=0.549, lr=0.002]Steps:  91%|█████████ | 91/100 [01:35<00:09,  1.05s/it, loss=0.56, lr=0.002] Steps:  91%|█████████ | 91/100 [01:35<00:09,  1.05s/it, loss=0.512, lr=0.002]Steps:  91%|█████████ | 91/100 [01:36<00:09,  1.05s/it, loss=0.426, lr=0.002]Steps:  91%|█████████ | 91/100 [01:36<00:09,  1.05s/it, loss=0.557, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:36<00:08,  1.05s/it, loss=0.557, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:36<00:08,  1.05s/it, loss=0.524, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:36<00:08,  1.05s/it, loss=0.559, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:37<00:08,  1.05s/it, loss=0.387, lr=0.002]Steps:  92%|█████████▏| 92/100 [01:37<00:08,  1.05s/it, loss=0.509, lr=0.002]Steps:  93%|█████████▎| 93/100 [01:37<00:07,  1.05s/it, loss=0.509, lr=0.002]Steps:  93%|█████████▎| 93/100 [01:37<00:07,  1.05s/it, loss=0.559, lr=0.002]Steps:  93%|█████████▎| 93/100 [01:37<00:07,  1.05s/it, loss=0.403, lr=0.002]Steps:  93%|█████████▎| 93/100 [01:38<00:07,  1.05s/it, loss=0.542, lr=0.002]Steps:  93%|█████████▎| 93/100 [01:38<00:07,  1.05s/it, loss=0.562, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:38<00:06,  1.05s/it, loss=0.562, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:38<00:06,  1.05s/it, loss=0.372, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:39<00:06,  1.05s/it, loss=0.503, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:39<00:06,  1.05s/it, loss=0.559, lr=0.002]Steps:  94%|█████████▍| 94/100 [01:39<00:06,  1.05s/it, loss=0.517, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:39<00:05,  1.05s/it, loss=0.517, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:39<00:05,  1.05s/it, loss=0.586, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:40<00:05,  1.05s/it, loss=0.503, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:40<00:05,  1.05s/it, loss=0.505, lr=0.002]Steps:  95%|█████████▌| 95/100 [01:40<00:05,  1.05s/it, loss=0.414, lr=0.002]Steps:  96%|█████████▌| 96/100 [01:40<00:04,  1.05s/it, loss=0.414, lr=0.002]Steps:  96%|█████████▌| 96/100 [01:40<00:04,  1.05s/it, loss=0.507, lr=0.002]Steps:  96%|█████████▌| 96/100 [01:41<00:04,  1.05s/it, loss=0.393, lr=0.002]Steps:  96%|█████████▌| 96/100 [01:41<00:04,  1.05s/it, loss=0.56, lr=0.002] Steps:  96%|█████████▌| 96/100 [01:41<00:04,  1.05s/it, loss=0.56, lr=0.002]Steps:  97%|█████████▋| 97/100 [01:41<00:03,  1.05s/it, loss=0.56, lr=0.002]Steps:  97%|█████████▋| 97/100 [01:41<00:03,  1.05s/it, loss=0.41, lr=0.002]Steps:  97%|█████████▋| 97/100 [01:42<00:03,  1.05s/it, loss=0.551, lr=0.002]Steps:  97%|█████████▋| 97/100 [01:42<00:03,  1.05s/it, loss=0.571, lr=0.002]Steps:  97%|█████████▋| 97/100 [01:42<00:03,  1.05s/it, loss=0.411, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:42<00:02,  1.05s/it, loss=0.411, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:42<00:02,  1.05s/it, loss=0.418, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:43<00:02,  1.05s/it, loss=0.573, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:43<00:02,  1.05s/it, loss=0.563, lr=0.002]Steps:  98%|█████████▊| 98/100 [01:43<00:02,  1.05s/it, loss=0.382, lr=0.002]Steps:  99%|█████████▉| 99/100 [01:44<00:01,  1.05s/it, loss=0.382, lr=0.002]Steps:  99%|█████████▉| 99/100 [01:44<00:01,  1.05s/it, loss=0.463, lr=0.002]Steps:  99%|█████████▉| 99/100 [01:44<00:01,  1.05s/it, loss=0.48, lr=0.002] Steps:  99%|█████████▉| 99/100 [01:44<00:01,  1.05s/it, loss=0.567, lr=0.002]Steps:  99%|█████████▉| 99/100 [01:44<00:01,  1.05s/it, loss=0.585, lr=0.002]Steps: 100%|██████████| 100/100 [01:45<00:00,  1.04s/it, loss=0.585, lr=0.002]Steps: 100%|██████████| 100/100 [01:45<00:00,  1.04s/it, loss=0.561, lr=0.002]Steps: 100%|██████████| 100/100 [01:45<00:00,  1.05s/it, loss=0.561, lr=0.002]
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'CLIPTokenizer'. 
The class this function is called from is 'MultiTokenCLIPTokenizer'.
{'requires_safety_checker'} was not found in config. Values will be initialized to default values.
The config attributes {'dropout': 0.0} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.
{'norm_num_groups', 'flip_sin_to_cos', 'use_linear_projection', 'downsample_padding', 'center_input_sample', 'only_cross_attention', 'mid_block_scale_factor', 'num_class_embeds', 'dual_cross_attention', 'upcast_attention', 'norm_eps', 'act_fn'} was not found in config. Values will be initialized to default values.
number of placeholder tokens are: 3
[49406, 49407]
[49406, 49408, 49409, 49410, 49407]
init_context =  torch.Size([3, 77, 768])
input_tensor 是张量类型
self.context torch.Size([2, 77, 768])
latent_cur =  torch.Size([4, 64, 64])
noise_loss_list[0].shape =  torch.Size([1, 4, 64, 64])
noist_list.shape =  torch.Size([50, 1, 4, 64, 64])
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:05,  9.43it/s]  6%|▌         | 3/50 [00:00<00:05,  8.68it/s]  8%|▊         | 4/50 [00:00<00:05,  8.32it/s] 10%|█         | 5/50 [00:00<00:05,  8.13it/s] 12%|█▏        | 6/50 [00:00<00:05,  8.03it/s] 14%|█▍        | 7/50 [00:00<00:05,  7.95it/s] 16%|█▌        | 8/50 [00:00<00:05,  7.90it/s] 18%|█▊        | 9/50 [00:01<00:05,  7.88it/s] 20%|██        | 10/50 [00:01<00:05,  7.85it/s] 22%|██▏       | 11/50 [00:01<00:04,  7.84it/s] 24%|██▍       | 12/50 [00:01<00:04,  7.81it/s] 26%|██▌       | 13/50 [00:01<00:04,  7.80it/s] 28%|██▊       | 14/50 [00:01<00:04,  7.81it/s] 30%|███       | 15/50 [00:01<00:04,  7.80it/s] 32%|███▏      | 16/50 [00:02<00:04,  7.79it/s] 34%|███▍      | 17/50 [00:02<00:04,  7.79it/s] 36%|███▌      | 18/50 [00:02<00:04,  7.80it/s] 38%|███▊      | 19/50 [00:02<00:03,  7.81it/s] 40%|████      | 20/50 [00:02<00:03,  7.79it/s] 42%|████▏     | 21/50 [00:02<00:03,  7.78it/s] 44%|████▍     | 22/50 [00:02<00:03,  7.78it/s] 46%|████▌     | 23/50 [00:02<00:03,  7.78it/s] 48%|████▊     | 24/50 [00:03<00:03,  7.80it/s] 50%|█████     | 25/50 [00:03<00:03,  7.80it/s] 52%|█████▏    | 26/50 [00:03<00:03,  7.79it/s] 54%|█████▍    | 27/50 [00:03<00:02,  7.78it/s] 56%|█████▌    | 28/50 [00:03<00:02,  7.77it/s] 58%|█████▊    | 29/50 [00:03<00:02,  7.76it/s] 60%|██████    | 30/50 [00:03<00:02,  7.77it/s] 62%|██████▏   | 31/50 [00:03<00:02,  7.78it/s] 64%|██████▍   | 32/50 [00:04<00:02,  7.78it/s] 66%|██████▌   | 33/50 [00:04<00:02,  7.78it/s] 68%|██████▊   | 34/50 [00:04<00:02,  7.78it/s] 70%|███████   | 35/50 [00:04<00:01,  7.78it/s] 72%|███████▏  | 36/50 [00:04<00:01,  7.77it/s] 74%|███████▍  | 37/50 [00:04<00:01,  7.77it/s] 76%|███████▌  | 38/50 [00:04<00:01,  7.77it/s] 78%|███████▊  | 39/50 [00:04<00:01,  7.78it/s] 80%|████████  | 40/50 [00:05<00:01,  7.79it/s] 82%|████████▏ | 41/50 [00:05<00:01,  7.77it/s] 84%|████████▍ | 42/50 [00:05<00:01,  7.77it/s] 86%|████████▌ | 43/50 [00:05<00:00,  7.76it/s] 88%|████████▊ | 44/50 [00:05<00:00,  7.75it/s] 90%|█████████ | 45/50 [00:05<00:00,  7.76it/s] 92%|█████████▏| 46/50 [00:05<00:00,  7.75it/s] 94%|█████████▍| 47/50 [00:05<00:00,  7.75it/s] 96%|█████████▌| 48/50 [00:06<00:00,  7.77it/s] 98%|█████████▊| 49/50 [00:06<00:00,  7.77it/s]100%|██████████| 50/50 [00:06<00:00,  7.77it/s]100%|██████████| 50/50 [00:06<00:00,  7.84it/s]
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
latent =  torch.Size([4, 4, 64, 64])
encoder_hidden_states =  torch.Size([4, 77, 768])
saving image ./output_images/12-6-5/__out__lion_1_p2_7.5_7.5_7.52023-12-07_17:43:37.774332.png
